{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0557d6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "import pickle as pkl\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "df_annotations = pd.read_csv(\"../../data/ctgov/annotations/all_annotations.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2e7a73",
   "metadata": {},
   "source": [
    "# Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8ebd7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../data/ctgov/protocols.pkl.gz\", \"rb\") as f:\n",
    "    file_to_pages = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9fbe5bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = []\n",
    "\n",
    "for i in range(len(df_annotations)):\n",
    "    file_name = df_annotations.file.iloc[i]\n",
    "    \n",
    "    pages= file_to_pages[file_name]\n",
    "\n",
    "    texts.append(\" \".join(pages))\n",
    "df_annotations[\"text\"] = texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77cd2264",
   "metadata": {},
   "outputs": [],
   "source": [
    "del file_to_pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3322e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_annotations_num_arms_known = df_annotations[~df_annotations.num_arms.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26b24be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_annotations_num_arms_known = df_annotations_num_arms_known.sample(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df0ea588",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_arms_clean(num):\n",
    "    if num >= 5:\n",
    "        num = 5\n",
    "    return num\n",
    "df_annotations_num_arms_known[\"num_arms_clean\"] = df_annotations_num_arms_known[\"num_arms\"].apply(get_num_arms_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e91853",
   "metadata": {},
   "source": [
    "# Train and evaluate the number of arms extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f49752a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"../../front_end\")\n",
    "from util.page_tokeniser import tokenise_pages, tokenise_text, tokenise_text_and_lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f807e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm', disable=['ner', 'tagger', 'parser', 'lemmatizer'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b2646ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2num = {'one': 1,\n",
    " 'two': 2,\n",
    " 'three': 3,\n",
    " 'four': 4,\n",
    " 'five': 5,\n",
    " 'six': 6,\n",
    " 'seven': 7,\n",
    " 'eight': 8,\n",
    " 'nine': 9,\n",
    " 'ten': 10,\n",
    " 'eleven': 11,\n",
    " 'twelve': 12,\n",
    " 'thirteen': 13,\n",
    " 'fourteen': 14,\n",
    " 'fifteen': 15,\n",
    " 'sixteen': 16,\n",
    " 'seventeen': 17,\n",
    " 'eighteen': 18,\n",
    " 'nineteen': 19,\n",
    " 'both': 2,\n",
    " 'single': 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b204d6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_words = list(word2num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "04d187ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(1, 20):\n",
    "    word2num[str(n)]= n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3dc8a7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers_above_3 = list([w for w in word2num if word2num[w] >= 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e4071f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher = Matcher(nlp.vocab)\n",
    "patterns = [ #[{\"LIKE_NUM\":True},  {\"LOWER\": {\"IN\": [\"treatment\", \"study\", \"dose\"]}, \"OP\":\"?\"}, {\"LOWER\": {\"IN\": [\"arm\", \"arms\", \"group\", \"groups\", \"subgroup\", \"subgroups\", \"cohort\", \"cohorts\"]}}],\n",
    "           [{\"LOWER\":{\"IN\":number_words}},  {\"LOWER\": {\"IN\": [\"treatment\", \"study\", \"dose\"]}}, {\"LOWER\": {\"IN\": [\"arm\", \"arms\", \"group\", \"groups\", \"subgroup\", \"subgroups\", \"cohort\", \"cohorts\"]}}],\n",
    "#            [{\"LOWER\":{\"IN\":number_words}},  {\"LOWER\": {\"IN\": [\"group\", \"groups\", \"subgroup\", \"subgroups\", \"cohort\", \"cohorts\"]}}],\n",
    "             [{\"LOWER\":{\"IN\":list(word2num)}},{\"LOWER\":\"-\", \"OP\":\"?\"}, {\"LOWER\": {\"IN\": [ \"armed\"]}}]\n",
    "]\n",
    "matcher.add(\"arms\", patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "da7c3630",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = spacy.tokens.doc.Doc(\n",
    "            nlp.vocab, words=[\"5\", \"arms\"])\n",
    "matcher(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2346b732",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenised_pages = [[\"5\", \"arms\"]]\n",
    "# if True:\n",
    "def process(self, tokenised_pages: list) -> tuple:\n",
    "    \"\"\"\n",
    "    Identify the trial phase.\n",
    "    :param tokenised_pages: List of lists of tokens of each page.\n",
    "    :return: The prediction (str) and a map from phase to the pages it's mentioned in.\n",
    "    \"\"\"\n",
    "\n",
    "    tokenised_pages = [[string.lower() for string in sublist] for sublist in tokenised_pages]\n",
    "\n",
    "    phase_to_pages = {}\n",
    "\n",
    "    for page_number, page_tokens in enumerate(tokenised_pages):\n",
    "        doc = spacy.tokens.doc.Doc(\n",
    "            nlp.vocab, words=page_tokens)\n",
    "        matches = matcher(doc)\n",
    "        for word, start, end in matches:\n",
    "            phase_number = doc[start:end]\n",
    "            if phase_number not in phase_to_pages:\n",
    "                phase_to_pages[phase_number] = []\n",
    "            phase_to_pages[phase_number].append(page_number)\n",
    "\n",
    "    phase_to_pages = sorted(phase_to_pages.items(), key=lambda v: len(v[1]), reverse=True)\n",
    "\n",
    "    prediction = 0\n",
    "    if len(phase_to_pages) == 1:\n",
    "        for word in phase_to_pages[0][0]:\n",
    "            if word.text in word2num:\n",
    "                prediction = word2num[word.text]\n",
    "                break\n",
    "    if prediction > 5:\n",
    "        prediction = 5\n",
    "                \n",
    "    phase_to_pages = [(phrase.text, value) for phrase, value in phase_to_pages]\n",
    "\n",
    "    return {\"prediction\": prediction, \"pages\": dict(phase_to_pages)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b8ac14ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val = df_annotations_num_arms_known[df_annotations_num_arms_known.train_val == \"val\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481e7a78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1ab67890",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_annotations_num_arms_known[df_annotations_num_arms_known.train_val == \"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "19fb604a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.metrics import accuracy_score, auc, roc_curve\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.naive_bayes import MultinomialNB, ComplementNB\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52774314",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_FEATURES = 1500\n",
    "\n",
    "stops = set(stopwords.words('english')).union(set(stopwords.words('french')))\n",
    "stops.remove(\"both\")\n",
    "stops.remove(\"all\")\n",
    "\n",
    "# Specially engineered regex to include 95%, 95%ci, etc\n",
    "vectoriser = CountVectorizer(lowercase=True,\n",
    "                             token_pattern=r'[a-z][a-z]+', \n",
    "                            \n",
    "                            vocabulary={\n",
    "                                \"arm\", \"group\", \"subgroup\", \"cohort\", \"arms\", \"groups\", \"subgroups\", \"cohorts\",\n",
    "                    \"randomise\", \"randomize\", \"randomisation\", \"randomization\", \"randomised\", \"randomized\",\n",
    "                    \"placebo\", \"unblinded\", \"unblinding\", \"blinded\", \"blinding\", \"blind\", \"compare\", \"double\",\n",
    "                    \"controlled\", \"control\", \"differences\", \"vs\", \"outcomes\", \"hypothesis\", \"experimental\", \"compared\",\n",
    "                    \"effects\", \"variables\", \"variables\", \"ratio\", \"versus\", \"outcome\", \"monotherapy\", \"polytherapy\", \"proprietary\",\n",
    "                    \"criterion\", \"healthy\", \"remission\", \"separately\", \"separate\", \"separated\", \"assay\", \"dosing\", \"dose\", \"doses\",\n",
    "                    \"treatment\", \"treatments\", \"study\", \"studies\", \"either\", \"both\"}\n",
    "                            )\n",
    "transformer = TfidfTransformer()\n",
    "\n",
    "nb = MultinomialNB()\n",
    "nb = ComplementNB()\n",
    "model = make_pipeline(vectoriser, transformer, nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3146265",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.num_arms_clean.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f1a8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(df_train.text, df_train.num_arms_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fe7085",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val[\"pred_num_arms_nb\"]  = model.predict(df_val.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace3024b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val.pred_num_arms_nb.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32da3572",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502c8475",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_arms(text):\n",
    "    toks = tokenise_text_and_lowercase(text)\n",
    "    result = process(None, [toks])\n",
    "    return result[\"prediction\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50d45ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pages(text):\n",
    "    toks = tokenise_text_and_lowercase(text)\n",
    "    result = process(None, [toks])\n",
    "    return result[\"pages\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a66fe16",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_val[\"pred_num_arms_spacy\"] = df_val.text.apply(get_num_arms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d9d9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val[\"pred_num_arms_spacy\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6158e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_num_arms = []\n",
    "for i in range(len(df_val)):\n",
    "    if df_val.pred_num_arms_spacy.iloc[i] > 0:\n",
    "        pred = df_val.pred_num_arms_spacy.iloc[i]\n",
    "    else:\n",
    "        pred = df_val.pred_num_arms_nb.iloc[i]\n",
    "    pred_num_arms.append(pred)\n",
    "df_val[\"pred_num_arms\"] = pred_num_arms\n",
    "pred_num_arms= df_val[\"pred_num_arms\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6384bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val[\"pages\"] = df_val.text.apply(get_pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1e7efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_num_arms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077e3eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_num_arms.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d636fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_arms_ground_truths = df_val.num_arms_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5f8d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = accuracy_score(num_arms_ground_truths, pred_num_arms)\n",
    "print (f\"Num arms accuracy {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c5d1be",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay.from_predictions(num_arms_ground_truths, pred_num_arms)\n",
    "plt.xticks(rotation=90)\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91311d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(num_arms_ground_truths[pred_num_arms > 0], pred_num_arms[pred_num_arms > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f602d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b0d6cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8e7415",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fake_document = \" \".join(vectoriser.vocabulary_)\n",
    "vectorised_document = vectoriser.transform([fake_document])\n",
    "transformed_document = transformer.transform(vectorised_document)\n",
    "probas = np.zeros((transformed_document.shape[1]))\n",
    "\n",
    "for prediction_idx in range(5):\n",
    "    print(f\"Strongest predictors for class {prediction_idx}\\n\")\n",
    "    for i in range(transformed_document.shape[1]):\n",
    "        zeros = np.zeros(transformed_document.shape)\n",
    "        zeros[0, i] = transformed_document[0, i]\n",
    "        proba = nb.predict_log_proba(zeros)\n",
    "        probas[i] = proba[0, prediction_idx]\n",
    "\n",
    "    for ctr, j in enumerate(np.argsort(-probas)):\n",
    "        for w, i in vectoriser.vocabulary_.items():\n",
    "            if i == j:\n",
    "                print(f\"{ctr}\\t{w}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6add3d7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84e4ad5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py310] *",
   "language": "python",
   "name": "conda-env-py310-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
