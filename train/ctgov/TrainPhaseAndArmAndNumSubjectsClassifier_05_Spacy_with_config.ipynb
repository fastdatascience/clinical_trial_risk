{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fastdatascience/clinical_trial_risk/blob/fixes_nov_2022/train/ctgov/TrainPhaseAndArmAndNumSubjectsClassifier_05_Spacy_with_config.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install spacy-transformers"
      ],
      "metadata": {
        "id": "EpG7zWxUgCKW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29998edd-7df3-4518-f4ec-c85214a0f28a"
      },
      "id": "EpG7zWxUgCKW",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting spacy-transformers\n",
            "  Downloading spacy_transformers-1.1.8-py2.py3-none-any.whl (53 kB)\n",
            "\u001b[K     |████████████████████████████████| 53 kB 1.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from spacy-transformers) (1.12.1+cu113)\n",
            "Collecting spacy-alignments<1.0.0,>=0.7.2\n",
            "  Downloading spacy_alignments-0.8.6-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 17.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: srsly<3.0.0,>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy-transformers) (2.4.5)\n",
            "Requirement already satisfied: spacy<4.0.0,>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy-transformers) (3.4.2)\n",
            "Collecting transformers<4.22.0,>=3.4.0\n",
            "  Downloading transformers-4.21.3-py3-none-any.whl (4.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.7 MB 87.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.4.0->spacy-transformers) (4.1.1)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.4.0->spacy-transformers) (8.1.5)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.4.0->spacy-transformers) (0.6.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.4.0->spacy-transformers) (2.23.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.4.0->spacy-transformers) (1.10.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.4.0->spacy-transformers) (57.4.0)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.4.0->spacy-transformers) (2.0.8)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.4.0->spacy-transformers) (1.0.3)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.4.0->spacy-transformers) (2.0.7)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.4.0->spacy-transformers) (1.21.6)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.4.0->spacy-transformers) (1.0.9)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.4.0->spacy-transformers) (3.0.10)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.4.0->spacy-transformers) (21.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.4.0->spacy-transformers) (2.11.3)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.4.0->spacy-transformers) (0.10.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.4.0->spacy-transformers) (3.0.8)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.4.0->spacy-transformers) (4.64.1)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.4.0->spacy-transformers) (0.4.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy<4.0.0,>=3.4.0->spacy-transformers) (3.3.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy<4.0.0,>=3.4.0->spacy-transformers) (3.10.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<4.0.0,>=3.4.0->spacy-transformers) (3.0.9)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<4.0.0,>=3.4.0->spacy-transformers) (5.2.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.4.0->spacy-transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.4.0->spacy-transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.4.0->spacy-transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.4.0->spacy-transformers) (2022.9.24)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.7/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<4.0.0,>=3.4.0->spacy-transformers) (0.0.3)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.7/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<4.0.0,>=3.4.0->spacy-transformers) (0.7.9)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.10.1-py3-none-any.whl (163 kB)\n",
            "\u001b[K     |████████████████████████████████| 163 kB 85.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<4.22.0,>=3.4.0->spacy-transformers) (2022.6.2)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 24.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers<4.22.0,>=3.4.0->spacy-transformers) (4.13.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<4.22.0,>=3.4.0->spacy-transformers) (3.8.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers<4.22.0,>=3.4.0->spacy-transformers) (6.0)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy<4.0.0,>=3.4.0->spacy-transformers) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<4.0.0,>=3.4.0->spacy-transformers) (2.0.1)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers, spacy-alignments, spacy-transformers\n",
            "Successfully installed huggingface-hub-0.10.1 spacy-alignments-0.8.6 spacy-transformers-1.1.8 tokenizers-0.12.1 transformers-4.21.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!python -m spacy init fill-config base_config.cfg spacy_textcat_05.cfg"
      ],
      "metadata": {
        "id": "3t_pIMzNf0jN"
      },
      "id": "3t_pIMzNf0jN",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "ad812236",
      "metadata": {
        "id": "ad812236"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import os\n",
        "import sys\n",
        "import pickle as pkl\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from IPython.display import display\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import json\n",
        "\n",
        "# df_annotations = pd.read_csv(\"all_annotations.csv\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7ea7d33",
      "metadata": {
        "id": "e7ea7d33"
      },
      "source": [
        "# Get data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "xCe1anFkGSrt",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xCe1anFkGSrt",
        "outputId": "c8eebca1-3ba3-4305-e7bf-0a49ee4f5f1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "FdcTHlHsGWnk",
      "metadata": {
        "id": "FdcTHlHsGWnk"
      },
      "outputs": [],
      "source": [
        "df_annotations= pd.read_csv(\"/content/drive/MyDrive/data/filtered_for_phase_arms_subjects_02.csv.bz2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "4048908c",
      "metadata": {
        "id": "4048908c"
      },
      "outputs": [],
      "source": [
        "#df_annotations= pd.read_csv(\"filtered_for_phase_arms_subjects_02.csv.bz2\")\n",
        "# df_annotations= pd.read_csv(\"/home/thomas/Downloads/filtered_for_phase_arms_subjects.csv.bz2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "wGilqqbTi76N",
      "metadata": {
        "id": "wGilqqbTi76N"
      },
      "outputs": [],
      "source": [
        "#df_annotations.text = df_annotations.text.apply(lambda t : t[:10000] if len(t) > 10000 else t)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "mZ82V337HouW",
      "metadata": {
        "id": "mZ82V337HouW"
      },
      "outputs": [],
      "source": [
        "def get_num_subjects_clean(num):\n",
        "    if pd.isna(num):\n",
        "        return None\n",
        "    if num >= 10000:\n",
        "        return \"10000+\"\n",
        "    if num >= 1000:\n",
        "        return \"1000+\"\n",
        "    if num >= 500:\n",
        "        return \"500+\"\n",
        "    if num >= 200:\n",
        "        return \"200+\"\n",
        "    if num >= 100:\n",
        "        return \"100+\"\n",
        "    if num >= 50:\n",
        "        return \"50+\"\n",
        "    if num >= 25:\n",
        "        return \"25+\"\n",
        "    return \"1-24\"\n",
        "df_annotations[\"num_subjects_clean\"] = df_annotations[\"num_subjects\"].apply(get_num_subjects_clean)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "cKMRrJjQIF7U",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cKMRrJjQIF7U",
        "outputId": "573e73d4-f15e-489f-8474-81f4c59e7f85"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1-24      2980\n",
              "25+       2119\n",
              "50+       2016\n",
              "100+      1674\n",
              "200+      1656\n",
              "500+       816\n",
              "1000+      547\n",
              "10000+     112\n",
              "Name: num_subjects_clean, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "df_annotations[\"num_subjects_clean\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "89e1c4f0",
      "metadata": {
        "id": "89e1c4f0"
      },
      "outputs": [],
      "source": [
        "# df_annotations = pd.read_csv(\"filtered_for_phase.csv.bz2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "a12043ac",
      "metadata": {
        "id": "a12043ac"
      },
      "outputs": [],
      "source": [
        "# del file_to_pages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "bbe0ba77",
      "metadata": {
        "id": "bbe0ba77"
      },
      "outputs": [],
      "source": [
        "phase_map = {\"Phase 2\":\"2\",\n",
        "\"Phase 3\":\"3\",\n",
        "\"Phase 4\":\"4\",\n",
        "\"Phase 1\":\"1\",\n",
        "\"Phase 1/Phase 2\":\"1.5\",\n",
        "\"Not Applicable\":\"0\",\n",
        "\"Phase 2/Phase 3\":\"2.5\",\n",
        "\"Early Phase 1\":\"0.5\"}\n",
        "df_annotations[\"phase_clean\"] = df_annotations[\"phase\"].apply(lambda x : phase_map.get(x, None))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "DNjQhXOVrQxj",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DNjQhXOVrQxj",
        "outputId": "ee4a3b75-6b70-478e-a271-5a0b4ccc37e1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['0', '0.5', '1', '1.5', '2', '2.5', '3', '4']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "phase_clean_map = {}\n",
        "for idx, val in enumerate(sorted(set(phase_map.values()), key = lambda x : float(x))):\n",
        "  phase_clean_map[val] = idx\n",
        "# invert the dictionary\n",
        "phase_lookup = {v: k for k, v in phase_clean_map.items()}\n",
        "\n",
        "phase_list = [phase_lookup[x] for x in sorted(phase_lookup)]\n",
        "phase_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "f99e999b",
      "metadata": {
        "id": "f99e999b"
      },
      "outputs": [],
      "source": [
        "def get_num_arms_clean(num):\n",
        "    if pd.isna(num):\n",
        "        return None\n",
        "    if num >= 5:\n",
        "        num = 5\n",
        "    return num\n",
        "df_annotations[\"num_arms_clean\"] = df_annotations[\"num_arms\"].apply(get_num_arms_clean)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Tq8Iseh1e_uQ",
      "metadata": {
        "id": "Tq8Iseh1e_uQ"
      },
      "source": [
        "# Begin Spacy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "0HHgTj8Qfub9",
      "metadata": {
        "id": "0HHgTj8Qfub9"
      },
      "outputs": [],
      "source": [
        "num_subjects_clean_map = {}\n",
        "for idx, val in enumerate(sorted(set(df_annotations[~df_annotations.num_subjects_clean.isna()].num_subjects_clean), key = lambda x : int(re.sub(r'\\D.*$', '', x)))):\n",
        "  num_subjects_clean_map[val] = idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "6jQQHMvxkC2l",
      "metadata": {
        "id": "6jQQHMvxkC2l"
      },
      "outputs": [],
      "source": [
        "# invert the dictionary\n",
        "num_subjects_lookup = {v: k for k, v in num_subjects_clean_map.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "C6fm756mlUSk",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C6fm756mlUSk",
        "outputId": "55929821-2307-425d-c2e0-0a94aa65cda2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['1-24', '25+', '50+', '100+', '200+', '500+', '1000+', '10000+']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "num_subjects_list = [num_subjects_lookup[x] for x in sorted(num_subjects_lookup)]\n",
        "num_subjects_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "sDIKJA57hR-K",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sDIKJA57hR-K",
        "outputId": "915ba4a3-1bd9-483b-d986-63049964516f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'1-24': 0,\n",
              " '25+': 1,\n",
              " '50+': 2,\n",
              " '100+': 3,\n",
              " '200+': 4,\n",
              " '500+': 5,\n",
              " '1000+': 6,\n",
              " '10000+': 7}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "num_subjects_clean_map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "EFTomf_xfjTS",
      "metadata": {
        "id": "EFTomf_xfjTS"
      },
      "outputs": [],
      "source": [
        "def get_one_hot_num_subjects(x):\n",
        "  a = [0] * len(num_subjects_clean_map)\n",
        "  if x is None:\n",
        "    return a\n",
        "  a[num_subjects_clean_map[x]] = 1\n",
        "  return a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "GCf8jZQZiBbC",
      "metadata": {
        "id": "GCf8jZQZiBbC"
      },
      "outputs": [],
      "source": [
        "df_annotations[\"num_subjects_one_hot\"] = df_annotations[\"num_subjects_clean\"].apply(get_one_hot_num_subjects)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "RoXplcZ6q3N3",
      "metadata": {
        "id": "RoXplcZ6q3N3"
      },
      "outputs": [],
      "source": [
        "df_annotations[\"num_subjects_one_hot\"] = df_annotations[\"num_subjects_clean\"].apply(get_one_hot_num_subjects)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "bGkQ4LeYq3QR",
      "metadata": {
        "id": "bGkQ4LeYq3QR"
      },
      "outputs": [],
      "source": [
        "def get_one_hot_num_arms(x):\n",
        "  a = [0] * 5\n",
        "  if x is not None and not pd.isna(x):\n",
        "    a[int(x - 1)] = 1\n",
        "  return a\n",
        "df_annotations[\"num_arms_one_hot\"] = df_annotations[\"num_arms_clean\"].apply(get_one_hot_num_arms)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "POLLhzW_rFvz",
      "metadata": {
        "id": "POLLhzW_rFvz"
      },
      "outputs": [],
      "source": [
        "def get_one_hot_phase(x):\n",
        "  a = [0] * len(phase_clean_map)\n",
        "  if x is None:\n",
        "    return a\n",
        "  a[phase_clean_map[x]] = 1\n",
        "  return a\n",
        "df_annotations[\"phase_one_hot\"] = df_annotations[\"phase_clean\"].apply(get_one_hot_phase)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ondugbdEsLJ7",
      "metadata": {
        "id": "ondugbdEsLJ7"
      },
      "source": [
        "Concatenate the three bits of one-hot data into one column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "eykeDEeFr56g",
      "metadata": {
        "id": "eykeDEeFr56g"
      },
      "outputs": [],
      "source": [
        "concatenated_one_hot = []\n",
        "for i in range(len(df_annotations)):\n",
        "  concatenated = list(df_annotations.phase_one_hot.iloc[i]) + \\\n",
        "  list(df_annotations.num_arms_one_hot.iloc[i]) + \\\n",
        "  list(df_annotations.num_subjects_one_hot.iloc[i]) + [df_annotations.has_sap.iloc[i]]\n",
        "  concatenated_one_hot.append(concatenated)\n",
        "df_annotations[\"concatenated_one_hot\"] = concatenated_one_hot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "eFM7jbfutXfu",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eFM7jbfutXfu",
        "outputId": "416d6f6c-ce1e-4753-b1c6-4cc72220aa92"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "nan"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "np.sum(np.asarray([np.asarray(x) for x in df_annotations[\"concatenated_one_hot\"]]), axis=1).mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "YmCgmZh3tmkn",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YmCgmZh3tmkn",
        "outputId": "7d7b6d45-6c5b-4424-976f-39ad4221a530"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 519.,  135., 1154.,  983., 4317.,  297., 2725., 1461., 3086.,\n",
              "       5228., 1456.,  908.,  913., 2980., 2119., 2016., 1674., 1656.,\n",
              "        816.,  547.,  112.,   nan])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "np.sum(np.asarray([np.asarray(x) for x in df_annotations[\"concatenated_one_hot\"]]), axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "yuUe_QwxsQRE",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yuUe_QwxsQRE",
        "outputId": "b8837c7f-45b1-4942-9bb1-842d14cb8308"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 22 classes in this multi-label classifier\n"
          ]
        }
      ],
      "source": [
        "num_classes = len(concatenated)\n",
        "print (f\"There are {num_classes} classes in this multi-label classifier\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "F_VhjeihirIu",
      "metadata": {
        "id": "F_VhjeihirIu"
      },
      "outputs": [],
      "source": [
        "df_train = df_annotations[df_annotations.train_val == \"train\"]\n",
        "df_val = df_annotations[df_annotations.train_val == \"val\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "pIWANTOGqDkg",
      "metadata": {
        "id": "pIWANTOGqDkg"
      },
      "outputs": [],
      "source": [
        "df_train_got_some_ground_truths = df_train[~df_train.num_subjects_clean.isna() | ~df_train.num_arms_clean.isna() | ~df_train.phase_clean.isna()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "yfw08MW2sYTw",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yfw08MW2sYTw",
        "outputId": "32140f40-68ef-4ef2-d5a8-6f8360339b34"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9535, 9538)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "len(df_train_got_some_ground_truths), len(df_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e6da254a",
      "metadata": {
        "id": "e6da254a"
      },
      "source": [
        "# Begin Spacy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "eb7993bd",
      "metadata": {
        "id": "eb7993bd"
      },
      "outputs": [],
      "source": [
        "# TRAINING_DATA = [\n",
        "#     [\"My little kitty is so special\", {\"KAT0\": True}],\n",
        "#     [\"Dude, Totally, Yeah, Video Games\", {\"KAT1\": True}],\n",
        "#     [\"Should I pay $1,000 for the iPhone X?\", {\"KAT1\": True}],\n",
        "#     [\"The iPhone 8 reviews are here\", {\"KAT1\": True}],\n",
        "#     [\"Noa is a great cat name.\", {\"KAT0\": True}],\n",
        "#     [\"We got a new kitten!\", {\"KAT0\": True}]\n",
        "# ]\n",
        "\n",
        "# TRAINING_DATA = []\n",
        "# for idx in range(len(df_train)):\n",
        "#     cats = {}\n",
        "#     for a in range(num_classes):\n",
        "#         cats[str(a)] = df_annotations[\"concatenated_one_hot\"].iloc[idx][a]\n",
        "\n",
        "#     text = df_train.text.iloc[idx]\n",
        "#     if len(text) > 1000000:\n",
        "#         text = text[:1000000]\n",
        "    \n",
        "#     TRAINING_DATA.append([text , cats])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocess everything into two DocBins so that we can train from the command line with spaCy"
      ],
      "metadata": {
        "id": "vJX8GSp2k1jB"
      },
      "id": "vJX8GSp2k1jB"
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.blank(\"en\")\n",
        "from spacy.tokens import DocBin\n",
        "\n",
        "docs_train = []\n",
        "for i in range(10):\n",
        "  docs_train.append(DocBin())\n",
        "docs_val = DocBin()\n",
        "\n",
        "for idx in range(len(df_annotations)):\n",
        "  if idx % 100 == 0:\n",
        "    print (idx, len(df_annotations))\n",
        "  if df_annotations.train_val.iloc[idx] == \"train\":\n",
        "    docs_list = docs_train[idx % 10]\n",
        "  else:\n",
        "    docs_list = docs_val\n",
        "  text = str(df_annotations.text.iloc[idx])\n",
        "  if len(text) > 100000:\n",
        "      text = text[:100000]\n",
        "  doc = nlp(text)\n",
        "\n",
        "  cats = {}\n",
        "  for a in range(num_classes):\n",
        "        cats[str(a)] = df_annotations[\"concatenated_one_hot\"].iloc[idx][a]\n",
        "  doc.cats = cats\n",
        "\n",
        "  docs_list.add(doc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zKHF4luDhdK1",
        "outputId": "06972baa-d1da-4f88-8633-b1ddec8d0fc0"
      },
      "id": "zKHF4luDhdK1",
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 11926\n",
            "100 11926\n",
            "200 11926\n",
            "300 11926\n",
            "400 11926\n",
            "500 11926\n",
            "600 11926\n",
            "700 11926\n",
            "800 11926\n",
            "900 11926\n",
            "1000 11926\n",
            "1100 11926\n",
            "1200 11926\n",
            "1300 11926\n",
            "1400 11926\n",
            "1500 11926\n",
            "1600 11926\n",
            "1700 11926\n",
            "1800 11926\n",
            "1900 11926\n",
            "2000 11926\n",
            "2100 11926\n",
            "2200 11926\n",
            "2300 11926\n",
            "2400 11926\n",
            "2500 11926\n",
            "2600 11926\n",
            "2700 11926\n",
            "2800 11926\n",
            "2900 11926\n",
            "3000 11926\n",
            "3100 11926\n",
            "3200 11926\n",
            "3300 11926\n",
            "3400 11926\n",
            "3500 11926\n",
            "3600 11926\n",
            "3700 11926\n",
            "3800 11926\n",
            "3900 11926\n",
            "4000 11926\n",
            "4100 11926\n",
            "4200 11926\n",
            "4300 11926\n",
            "4400 11926\n",
            "4500 11926\n",
            "4600 11926\n",
            "4700 11926\n",
            "4800 11926\n",
            "4900 11926\n",
            "5000 11926\n",
            "5100 11926\n",
            "5200 11926\n",
            "5300 11926\n",
            "5400 11926\n",
            "5500 11926\n",
            "5600 11926\n",
            "5700 11926\n",
            "5800 11926\n",
            "5900 11926\n",
            "6000 11926\n",
            "6100 11926\n",
            "6200 11926\n",
            "6300 11926\n",
            "6400 11926\n",
            "6500 11926\n",
            "6600 11926\n",
            "6700 11926\n",
            "6800 11926\n",
            "6900 11926\n",
            "7000 11926\n",
            "7100 11926\n",
            "7200 11926\n",
            "7300 11926\n",
            "7400 11926\n",
            "7500 11926\n",
            "7600 11926\n",
            "7700 11926\n",
            "7800 11926\n",
            "7900 11926\n",
            "8000 11926\n",
            "8100 11926\n",
            "8200 11926\n",
            "8300 11926\n",
            "8400 11926\n",
            "8500 11926\n",
            "8600 11926\n",
            "8700 11926\n",
            "8800 11926\n",
            "8900 11926\n",
            "9000 11926\n",
            "9100 11926\n",
            "9200 11926\n",
            "9300 11926\n",
            "9400 11926\n",
            "9500 11926\n",
            "9600 11926\n",
            "9700 11926\n",
            "9800 11926\n",
            "9900 11926\n",
            "10000 11926\n",
            "10100 11926\n",
            "10200 11926\n",
            "10300 11926\n",
            "10400 11926\n",
            "10500 11926\n",
            "10600 11926\n",
            "10700 11926\n",
            "10800 11926\n",
            "10900 11926\n",
            "11000 11926\n",
            "11100 11926\n",
            "11200 11926\n",
            "11300 11926\n",
            "11400 11926\n",
            "11500 11926\n",
            "11600 11926\n",
            "11700 11926\n",
            "11800 11926\n",
            "11900 11926\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# docs_train.to_disk(\"train.spacy\")\n",
        "docs_val.to_disk(\"dev.spacy\")"
      ],
      "metadata": {
        "id": "7LLBAyjkisjm"
      },
      "id": "7LLBAyjkisjm",
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs_val.to_disk(\"/content/drive/MyDrive/data/dev.spacy\")"
      ],
      "metadata": {
        "id": "uhVOW2-Sp70P"
      },
      "id": "uhVOW2-Sp70P",
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !mkdir train.spacy\n",
        "# !mkdir /content/drive/MyDrive/data/train.spacy\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbV7xnZip2Wj",
        "outputId": "c77d8feb-7132-4105-b334-0630bdadba88"
      },
      "id": "bbV7xnZip2Wj",
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/content/drive/MyDrive/data/train.spacy’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for idx, doc_bin_train in enumerate(docs_train):\n",
        "  doc_bin_train.to_disk(f\"train.spacy/train_doc_bin{idx}.spacy\")\n",
        "  doc_bin_train.to_disk(f\"/content/drive/MyDrive/data/train.spacy/train_doc_bin{idx}.spacy\")"
      ],
      "metadata": {
        "id": "k3qf7_xEo_Dx"
      },
      "id": "k3qf7_xEo_Dx",
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Begin training using spaCy CLI"
      ],
      "metadata": {
        "id": "h14ok40dsYqT"
      },
      "id": "h14ok40dsYqT"
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy train ./spacy_textcat_05.cfg --output /content/drive/MyDrive/data/output_textcat_05 --paths.train /content/drive/MyDrive/data/train.spacy --paths.dev /content/drive/MyDrive/data/dev.spacy --gpu-id 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PghYHYDVgktY",
        "outputId": "c018abe1-8807-4a61-9d22-dd5977aa9f6d"
      },
      "id": "PghYHYDVgktY",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-11-14 15:10:36.435730: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "\u001b[38;5;4mℹ Saving to output directory:\n",
            "/content/drive/MyDrive/data/output_textcat_05\u001b[0m\n",
            "\u001b[38;5;4mℹ Using GPU: 0\u001b[0m\n",
            "\u001b[1m\n",
            "=========================== Initializing pipeline ===========================\u001b[0m\n",
            "[2022-11-14 15:10:43,963] [INFO] Set up nlp object from config\n",
            "INFO:spacy:Set up nlp object from config\n",
            "[2022-11-14 15:10:43,975] [INFO] Pipeline: ['transformer', 'textcat_multilabel']\n",
            "INFO:spacy:Pipeline: ['transformer', 'textcat_multilabel']\n",
            "[2022-11-14 15:10:43,980] [INFO] Created vocabulary\n",
            "INFO:spacy:Created vocabulary\n",
            "[2022-11-14 15:10:43,981] [INFO] Finished initializing nlp object\n",
            "INFO:spacy:Finished initializing nlp object\n",
            "Downloading config.json: 100% 481/481 [00:00<00:00, 665kB/s]\n",
            "Downloading vocab.json: 100% 878k/878k [00:00<00:00, 2.46MB/s]\n",
            "Downloading merges.txt: 100% 446k/446k [00:00<00:00, 1.50MB/s]\n",
            "Downloading tokenizer.json: 100% 1.29M/1.29M [00:00<00:00, 3.68MB/s]\n",
            "Downloading pytorch_model.bin: 100% 478M/478M [00:07<00:00, 71.3MB/s]\n",
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.decoder.weight']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(\"/content/drive/MyDrive/data/output_textcat_05\")"
      ],
      "metadata": {
        "id": "mDLgJUS-jCCd"
      },
      "id": "mDLgJUS-jCCd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89103b7c",
      "metadata": {
        "id": "89103b7c"
      },
      "outputs": [],
      "source": [
        "predictions = []\n",
        "for idx in range(len(df_val)):\n",
        "    doc = nlp(df_val.text.apply(str).iloc[idx])\n",
        "    predictions.append(doc.cats)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4832e5ba",
      "metadata": {
        "id": "4832e5ba"
      },
      "outputs": [],
      "source": [
        "pred_proba = []\n",
        "for idx in range(len(df_val)):\n",
        "    pred_proba.append([predictions[idx][a] for a in range(num_classes)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "wia77Kufub2v",
      "metadata": {
        "id": "wia77Kufub2v"
      },
      "outputs": [],
      "source": [
        "y_pred_phase = []\n",
        "y_pred_num_arms = []\n",
        "y_pred_num_subjects = []\n",
        "y_pred_sap = []\n",
        "for idx in range(len(pred_proba)):\n",
        "  probas_this_instance = pred_proba[idx]\n",
        "  probas_phase = probas_this_instance[:len(phase_lookup)]\n",
        "  y_pred_phase.append(phase_lookup[int(np.argmax(probas_phase))])\n",
        "  probas_arms = probas_this_instance[len(phase_lookup):len(phase_lookup)+5]\n",
        "  y_pred_num_arms.append(1 + int(np.argmax(probas_arms)))\n",
        "  probas_subjects = probas_this_instance[len(phase_lookup)+5:-1]\n",
        "  y_pred_num_subjects.append(num_subjects_lookup[int(np.argmax(probas_subjects))])\n",
        "  probas_sap = probas_this_instance[-1:]\n",
        "  y_pred_sap.append(probas_sap[0] > 0.5)\n",
        "\n",
        "df_val[\"y_pred_phase\"] = y_pred_phase\n",
        "df_val[\"y_pred_num_arms\"] = y_pred_num_arms\n",
        "df_val[\"y_pred_num_subjects\"] = y_pred_num_subjects\n",
        "df_val[\"y_pred_sap\"] = y_pred_sap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "DbBjX9-agkVH",
      "metadata": {
        "id": "DbBjX9-agkVH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "ZNUbeGPw5KWg",
      "metadata": {
        "id": "ZNUbeGPw5KWg"
      },
      "source": [
        "## Phase"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "sznpf_e24NvP",
      "metadata": {
        "id": "sznpf_e24NvP"
      },
      "outputs": [],
      "source": [
        "acc = accuracy_score(df_val.phase_clean.apply(str), df_val[\"y_pred_phase\"])\n",
        "print (f\"Phase accuracy {acc}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "zLJ_MQih4T9n",
      "metadata": {
        "id": "zLJ_MQih4T9n"
      },
      "outputs": [],
      "source": [
        "ConfusionMatrixDisplay.from_predictions(df_val.phase_clean.apply(str), df_val[\"y_pred_phase\"])\n",
        "plt.xticks(rotation=90)\n",
        ";"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Fz_EyOrB5PXa",
      "metadata": {
        "id": "Fz_EyOrB5PXa"
      },
      "source": [
        "# Number of arms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "X8IsVDo34YTg",
      "metadata": {
        "id": "X8IsVDo34YTg"
      },
      "outputs": [],
      "source": [
        "acc = accuracy_score(df_val.num_arms_clean.apply(float).apply(str), df_val[\"y_pred_num_arms\"].apply(float).apply(str))\n",
        "print (f\"Num arms accuracy {acc}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "idb1W6VE4kIp",
      "metadata": {
        "id": "idb1W6VE4kIp"
      },
      "outputs": [],
      "source": [
        "ConfusionMatrixDisplay.from_predictions(df_val.num_arms_clean.apply(float).apply(str), df_val[\"y_pred_num_arms\"].apply(float).apply(str))\n",
        "plt.xticks(rotation=90)\n",
        ";"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "lLWC7P1k5NSX",
      "metadata": {
        "id": "lLWC7P1k5NSX"
      },
      "source": [
        "## Subjects"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rYhLhDmnNuAl",
      "metadata": {
        "id": "rYhLhDmnNuAl"
      },
      "outputs": [],
      "source": [
        "acc = accuracy_score(df_val.num_subjects_clean, df_val[\"y_pred_num_subjects\"])\n",
        "print (f\"Subjects accuracy {acc}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "XOiQVXB0NuHC",
      "metadata": {
        "id": "XOiQVXB0NuHC"
      },
      "outputs": [],
      "source": [
        "ConfusionMatrixDisplay.from_predictions(df_val.num_subjects_clean, df_val[\"y_pred_num_subjects\"], labels=num_subjects_list)\n",
        "plt.xticks(rotation=90)\n",
        ";"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "VzFHDCRtmBA6",
      "metadata": {
        "id": "VzFHDCRtmBA6"
      },
      "outputs": [],
      "source": [
        "num_correct = 0\n",
        "for idx in range(len(df_val)):\n",
        "  gt = num_subjects_clean_map[df_val[\"num_subjects_clean\"].iloc[idx]]\n",
        "  pred = num_subjects_clean_map[df_val[\"y_pred_num_subjects\"].iloc[idx]]\n",
        "  is_correct = int(np.abs(gt - pred) <= 1)\n",
        "  num_correct += is_correct\n",
        "print (\"Accuracy including adjacent groups\", num_correct/len(df_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1MU1NT4T_DLO",
      "metadata": {
        "id": "1MU1NT4T_DLO"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "tNsHUs9VBl4u",
      "metadata": {
        "id": "tNsHUs9VBl4u"
      },
      "source": [
        "## SAP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "w9KjSCypBmgs",
      "metadata": {
        "id": "w9KjSCypBmgs"
      },
      "outputs": [],
      "source": [
        "acc = accuracy_score(df_val.has_sap, df_val[\"y_pred_sap\"])\n",
        "print (f\"SAP accuracy {acc}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Yt36Zw4wB4P9",
      "metadata": {
        "id": "Yt36Zw4wB4P9"
      },
      "outputs": [],
      "source": [
        "ConfusionMatrixDisplay.from_predictions(df_val.has_sap, df_val[\"y_pred_sap\"])\n",
        "plt.xticks(rotation=90)\n",
        ";"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f5f4a3b1",
      "metadata": {
        "id": "f5f4a3b1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "96d94c76",
      "metadata": {
        "id": "96d94c76"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd10b723",
      "metadata": {
        "id": "dd10b723"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python [conda env:py310] *",
      "language": "python",
      "name": "conda-env-py310-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}