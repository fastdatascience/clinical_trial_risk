{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0557d6c8",
   "metadata": {
    "id": "0557d6c8"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "import pickle as pkl\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "#df_annotations = pd.read_csv(\"../../data/ctgov/annotations/all_annotations.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2e7a73",
   "metadata": {
    "id": "4b2e7a73"
   },
   "source": [
    "# Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8ebd7a5",
   "metadata": {
    "id": "c8ebd7a5"
   },
   "outputs": [],
   "source": [
    "# with open(\"../../data/ctgov/protocols.pkl.gz\", \"rb\") as f:\n",
    "#     file_to_pages = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6148cb3b",
   "metadata": {
    "id": "6148cb3b"
   },
   "outputs": [],
   "source": [
    "# import spacy\n",
    "# nlp = spacy.blank(\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fbe5bf0",
   "metadata": {
    "id": "9fbe5bf0",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# texts = []\n",
    "\n",
    "# for i in range(len(df_annotations)):\n",
    "#     file_name = df_annotations.file.iloc[i]\n",
    "    \n",
    "#     pages= file_to_pages[file_name]\n",
    "    \n",
    "#     text = \"\"\n",
    "#     for page in pages:\n",
    "#         doc = nlp(page)\n",
    "        \n",
    "#         is_include = [False] * len(doc)\n",
    "#         for tok in doc:\n",
    "#             if tok.text.lower() in {\"arm\", \"arms\", \"armed\", \"cohort\", \"cohorts\", \"group\", \"groups\"}:\n",
    "#                 for token_index in range(tok.i - 20, tok.i + 20):\n",
    "#                     if token_index >= 0 and token_index < len(doc):\n",
    "#                         is_include[token_index] = True\n",
    "        \n",
    "#         for token_index in range(len(doc)):\n",
    "#             if is_include[token_index]:\n",
    "#                 text += doc[token_index].text + doc[token_index].whitespace_\n",
    "                \n",
    "#     if text == \"\":\n",
    "#         print (\"nothing found\", file_name, df_annotations.num_arms.iloc[i])\n",
    "#     else:\n",
    "#         print (\"found\", file_name, df_annotations.num_arms.iloc[i])\n",
    "\n",
    "#     texts.append(text)\n",
    "# df_annotations[\"text\"] = texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cfac2830",
   "metadata": {
    "id": "cfac2830"
   },
   "outputs": [],
   "source": [
    "# df_annotations.to_pickle(\"filtered_for_arm.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "068abf18",
   "metadata": {
    "id": "068abf18"
   },
   "outputs": [],
   "source": [
    "df_annotations = pd.read_csv(\"filtered_for_arm.pkl.csv.bz2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93361b2c",
   "metadata": {
    "id": "93361b2c"
   },
   "outputs": [],
   "source": [
    "# del file_to_pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3322e30",
   "metadata": {
    "id": "f3322e30"
   },
   "outputs": [],
   "source": [
    "df_annotations_num_arms_known = df_annotations[~df_annotations.num_arms.isna() & ~df_annotations.text.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26b24be0",
   "metadata": {
    "id": "26b24be0"
   },
   "outputs": [],
   "source": [
    "#df_annotations_num_arms_known = df_annotations_num_arms_known.sample(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df0ea588",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "df0ea588",
    "outputId": "5e8d7ff8-6c65-4035-ed02-573d640f2367"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_17469/3303076186.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_annotations_num_arms_known[\"num_arms_clean\"] = df_annotations_num_arms_known[\"num_arms\"].apply(get_num_arms_clean)\n"
     ]
    }
   ],
   "source": [
    "def get_num_arms_clean(num):\n",
    "    if num >= 5:\n",
    "        num = 5\n",
    "    return num\n",
    "df_annotations_num_arms_known[\"num_arms_clean\"] = df_annotations_num_arms_known[\"num_arms\"].apply(get_num_arms_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df49af99",
   "metadata": {
    "id": "df49af99"
   },
   "outputs": [],
   "source": [
    "df_train = df_annotations_num_arms_known[df_annotations_num_arms_known.train_val == \"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6add3d7d",
   "metadata": {
    "id": "6add3d7d"
   },
   "outputs": [],
   "source": [
    "# TRAINING_DATA = [\n",
    "#     [\"My little kitty is so special\", {\"KAT0\": True}],\n",
    "#     [\"Dude, Totally, Yeah, Video Games\", {\"KAT1\": True}],\n",
    "#     [\"Should I pay $1,000 for the iPhone X?\", {\"KAT1\": True}],\n",
    "#     [\"The iPhone 8 reviews are here\", {\"KAT1\": True}],\n",
    "#     [\"Noa is a great cat name.\", {\"KAT0\": True}],\n",
    "#     [\"We got a new kitten!\", {\"KAT0\": True}]\n",
    "# ]\n",
    "\n",
    "TRAINING_DATA = []\n",
    "for idx in range(len(df_train)):\n",
    "    cats = {}\n",
    "    for a in range(1, 6):\n",
    "        cats[str(a)] = 0\n",
    "    cats[str(int(df_train.num_arms.iloc[idx]))] = 1\n",
    "    text = df_train.text.iloc[idx]\n",
    "    if len(text) > 1000000:\n",
    "        text = text[:1000000]\n",
    "    \n",
    "    TRAINING_DATA.append([text , cats])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b88f1c9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6b88f1c9",
    "outputId": "27ee3566-2f4b-43c0-c4b1-2d5eaafd46b6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-13 12:37:56.488795: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-13 12:37:56.646019: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-11-13 12:37:56.646038: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-11-13 12:37:56.674430: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-11-13 12:37:58.990246: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-13 12:37:58.990401: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-13 12:37:58.990412: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2022-11-13 12:38:05.194168: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-13 12:38:05.196181: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-11-13 12:38:05.196517: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2022-11-13 12:38:05.196814: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2022-11-13 12:38:05.197194: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2022-11-13 12:38:05.197647: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2022-11-13 12:38:05.197975: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2022-11-13 12:38:05.198455: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2022-11-13 12:38:05.198787: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2022-11-13 12:38:05.198825: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "# Add imports for example, as well as textcat config...\n",
    "from spacy.training import Example\n",
    "from spacy.pipeline.textcat import single_label_bow_config, single_label_default_config\n",
    "from thinc.api import Config\n",
    "import random\n",
    "\n",
    "# labels should be one-hot encoded\n",
    "\n",
    "\n",
    "\n",
    "# bow\n",
    "# config = Config().from_str(single_label_bow_config)\n",
    "\n",
    "# textensemble with attention\n",
    "config = Config().from_str(single_label_default_config)\n",
    "\n",
    "nlp = spacy.blank(\"en\")\n",
    "# now uses `add_pipe` instead\n",
    "category = nlp.add_pipe(\"textcat\", last=True, config=config)\n",
    "for a in range(1, 6):\n",
    "    category.add_label(str(a))\n",
    "\n",
    "\n",
    "# Start the training\n",
    "nlp.begin_training()\n",
    "\n",
    "# Loop for 10 iterations\n",
    "for itn in range(100):\n",
    "    # Shuffle the training data\n",
    "    random.shuffle(TRAINING_DATA)\n",
    "    losses = {}\n",
    "\n",
    "    # Batch the examples and iterate over them\n",
    "    for batch in spacy.util.minibatch(TRAINING_DATA, size=4):\n",
    "        texts = [nlp.make_doc(text) for text, entities in batch]\n",
    "        annotations = [{\"cats\": entities} for text, entities in batch]\n",
    "\n",
    "        # uses an example object rather than text/annotation tuple\n",
    "        examples = [Example.from_dict(doc, annotation) for doc, annotation in zip(\n",
    "            texts, annotations\n",
    "        )]\n",
    "        nlp.update(examples, losses=losses)\n",
    "    if itn % 20 == 0:\n",
    "        print(losses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9093f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_annotations_num_arms_known = df_annotations[~df_annotations.num_arms.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d07e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_annotations_num_arms_known[\"num_arms_clean\"] = df_annotations_num_arms_known[\"num_arms\"].apply(get_num_arms_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f720fbf",
   "metadata": {
    "id": "5f720fbf"
   },
   "outputs": [],
   "source": [
    "df_val = df_annotations_num_arms_known[df_annotations_num_arms_known.train_val == \"val\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a331d5",
   "metadata": {
    "id": "d9a331d5"
   },
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for idx in range(len(df_val)):\n",
    "    doc = nlp(df_val.text.apply(str).iloc[idx])\n",
    "    predictions.append(doc.cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ebd9f0",
   "metadata": {
    "id": "68ebd9f0",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_val[\"y_pred\"] = [int(max(p, key=p.get)) for p in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118aef49",
   "metadata": {
    "id": "118aef49"
   },
   "outputs": [],
   "source": [
    "num_arms_ground_truths = df_val.num_arms_clean\n",
    "pred_num_arms = df_val[\"y_pred\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73495a5c",
   "metadata": {
    "id": "73495a5c"
   },
   "outputs": [],
   "source": [
    "acc = accuracy_score(num_arms_ground_truths, pred_num_arms)\n",
    "print (f\"Num arms accuracy {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775ae91e",
   "metadata": {
    "id": "775ae91e"
   },
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay.from_predictions(num_arms_ground_truths, pred_num_arms)\n",
    "plt.xticks(rotation=90)\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62319c37",
   "metadata": {
    "id": "62319c37"
   },
   "outputs": [],
   "source": [
    "nlp.to_disk(\"arms_model_14_textcat_numarms.spacy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55177d2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:py310] *",
   "language": "python",
   "name": "conda-env-py310-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
