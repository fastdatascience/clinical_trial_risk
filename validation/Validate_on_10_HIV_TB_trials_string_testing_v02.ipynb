{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de9818b8",
   "metadata": {},
   "source": [
    "# Evaluate the entire processing of a set of ten protocols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd22924b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-23 13:01:01.731991: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-23 13:01:07.007591: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-01-23 13:01:07.007660: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-01-23 13:01:07.486780: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-01-23 13:01:26.138475: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-23 13:01:26.138998: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-23 13:01:26.139034: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../front_end')\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "import os\n",
    "from util.protocol_master_processor import MasterProcessor\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "037d556c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_testing = pd.read_excel(\"dsm_string_testing_v01.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68619cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_annotations = pd.read_csv(\"../data/ctgov/annotations/all_annotations.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04bd1bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_annotations.set_index(\"nct_id\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26c8c0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5b65cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../front_end')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71d87213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialising Phase Random Forest classifier models/phase_rf_classifier.pkl.bz2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/thomas/642d0db5-2c98-4156-b591-1a3572c5868c/anaconda3/envs/protocols/lib/python3.10/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.1.2 when using version 1.1.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/media/thomas/642d0db5-2c98-4156-b591-1a3572c5868c/anaconda3/envs/protocols/lib/python3.10/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 1.1.2 when using version 1.1.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/media/thomas/642d0db5-2c98-4156-b591-1a3572c5868c/anaconda3/envs/protocols/lib/python3.10/site-packages/spacy/util.py:833: UserWarning: [W095] Model 'en_pipeline' (0.0.0) was trained with spaCy v3.4 and may not be 100% compatible with the current version (3.2.3). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialising SAP document level classifier models/sap_classifier_document_level.pkl.bz2\n",
      "Initialising Num Arms classifier models/arms_classifier_document_level.pkl.bz2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/thomas/642d0db5-2c98-4156-b591-1a3572c5868c/anaconda3/envs/protocols/lib/python3.10/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator CountVectorizer from version 1.0.2 when using version 1.1.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/media/thomas/642d0db5-2c98-4156-b591-1a3572c5868c/anaconda3/envs/protocols/lib/python3.10/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator TfidfTransformer from version 1.0.2 when using version 1.1.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/media/thomas/642d0db5-2c98-4156-b591-1a3572c5868c/anaconda3/envs/protocols/lib/python3.10/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator MultinomialNB from version 1.0.2 when using version 1.1.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/media/thomas/642d0db5-2c98-4156-b591-1a3572c5868c/anaconda3/envs/protocols/lib/python3.10/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator Pipeline from version 1.0.2 when using version 1.1.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialising int classifier models/international_classifier.pkl.bz2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/thomas/642d0db5-2c98-4156-b591-1a3572c5868c/anaconda3/envs/protocols/lib/python3.10/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator BernoulliNB from version 1.0.2 when using version 1.1.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "master_processor = MasterProcessor(\"models/condition_classifier.pkl.bz2\",\n",
    "                                   \"models/phase_rf_classifier.pkl.bz2\",\n",
    "                                   \"models/spacy-textcat-phase-04-model-best\",\n",
    "                                   \"models/sap_classifier_document_level.pkl.bz2\",\n",
    "                                   \"models/sap_classifier.pkl.bz2\",\n",
    "                                   \"models/effect_estimate_classifier.pkl.bz2\",\n",
    "                                   \"models/num_subjects_classifier.pkl.bz2\",\n",
    "                                   \"models/subjects_classifier_document_level.pkl.bz2\",\n",
    "                                   \"models/arms_classifier_document_level.pkl.bz2\",\n",
    "                                   \"models/spacy-textcat-arms-21-model-best\",\n",
    "                                   \"models/spacy-textcat-international-11-model-best\",\n",
    "                                   \"models/spacy-textcat-country-16-model-best\",\n",
    "                                   \"models/international_classifier.pkl.bz2\",\n",
    "                                   \"models/country_ensemble_model.pkl.bz2\",\n",
    "                                   \"models/simulation_classifier.pkl.bz2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc5a49a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctgov_n = []\n",
    "ctgov_sap = []\n",
    "ctgov_countries = []\n",
    "\n",
    "for idx in range(len(df_testing)):\n",
    "    nct = df_testing.Protocol.iloc[idx]\n",
    "    n = None\n",
    "    sap = None\n",
    "    if nct in df_annotations.index:\n",
    "        n = df_annotations.num_subjects[nct]\n",
    "        sap = df_annotations.has_sap[nct]\n",
    "        countries = df_annotations.country[nct]\n",
    "    ctgov_n.append(n)\n",
    "    ctgov_sap.append(sap)\n",
    "    ctgov_countries.append(countries)\n",
    "df_testing.insert(df_testing.columns.get_loc(\"Rev_N\") + 1, \"CTGov_N\", ctgov_n)\n",
    "df_testing.insert(df_testing.columns.get_loc(\"Rev_SAP\") + 1, \"CTGov_SAP\", ctgov_sap)\n",
    "df_testing.insert(df_testing.columns.get_loc(\"Rev_countries\") + 1, \"CTGov_countries\", ctgov_countries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b26533cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56_NCT00752856_Prot_SAP_000.pdf\n",
      "21_NCT01896921_Prot_SAP_000.pdf\n",
      "94_NCT01933594_Prot_001.pdf\n",
      "04_NCT02217904_Prot_SAP_000.pdf\n",
      "26_NCT02263326_Prot_SAP_ICF_000.pdf\n",
      "61_NCT02707861_Prot_000.pdf\n",
      "75_NCT02788175_Prot_SAP_001.pdf\n",
      "47_NCT02946047_Prot_SAP_000.pdf\n",
      "41_NCT03262441_Prot_SAP_000.pdf\n",
      "99_NCT03351699_Prot_SAP_000.pdf\n",
      "86_NCT02342886_Prot_000.pdf\n",
      "28_NCT02153528_Prot_000.pdf\n",
      "48_NCT02583048_Prot_001.pdf\n",
      "76_NCT02193776_Prot_000.pdf\n",
      "72_NCT02410772_Prot_SAP_000.pdf\n",
      "84_NCT02114684_Prot_000.pdf\n"
     ]
    }
   ],
   "source": [
    "file_to_page = {}\n",
    "import json\n",
    "texts = []\n",
    "for idx in range(len(df_testing)):\n",
    "    nct = df_testing.Protocol.iloc[idx]\n",
    "    file_name = None\n",
    "    if nct in df_annotations.index:\n",
    "        file_name = df_annotations.file[nct]\n",
    "    print (file_name)\n",
    "    with open(\"../data/ctgov/json/\" + file_name + \".json\", \"r\", encoding=\"utf-8\") as f:\n",
    "        pages = json.load(f)\n",
    "    texts.append(pages)\n",
    "    file_to_page[file_name] = pages\n",
    "df_testing[\"pages\"] = texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d176b82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import bz2, pickle as pkl\n",
    "# with bz2.open(\"demo_data/demo_protocols.pkl.bz2\", \"wb\") as f:\n",
    "#     pkl.dump(file_to_page, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "795f675f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting the document into words (tokens)...\n",
      "There were 19078 words in the document.\n",
      "\n",
      "Searching for a likely pathology...\n",
      "This looks like an HIV trial.\n",
      "\n",
      "Searching for a phase...\n",
      "This looks like a Phase 2.0 trial.\n",
      "\n",
      "Neural network thought it was a Phase 2.0 trial.\n",
      "\n",
      "Searching for a statistical analysis plan...\n",
      "It does not look like the protocol contains a statistical analysis plan.\n",
      "\n",
      "Testing top pages for SAP with document level SAP Naive Bayes model to refine SAP prediction.\n",
      "\n",
      "Document level Naive Bayes model found SAP score 1 with score 0.5583868265125077.\n",
      "\n",
      "Searching for an effect estimate...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/thomas/642d0db5-2c98-4156-b591-1a3572c5868c/anaconda3/envs/protocols/lib/python3.10/site-packages/pandas/util/_decorators.py:311: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified probable effect estimate.\n",
      "\n",
      "Naive Bayes arms prediction probabilities: {'1': 0.17866803880560597, '2': 0.5245156463204527, '3+': 0.29681631487394244}.\n",
      "\n",
      "Spacy arms prediction probabilities: {'1': 0.008743556216359138, '2': 0.9820131659507751, '3+': 0.009243257343769073}.\n",
      "\n",
      "Searching for a number of arms...\n",
      "No explicit mention of arms found.\n",
      "\n",
      "Running Random Forest classifier for number of subjects...\n",
      "Searching for a number of subjects...\n",
      "It looks like the trial has 50 participants.\n",
      "\n",
      "Searching for the countries of investigation...\n",
      "It looks like the trial takes place in 1 country: PE\n",
      "\n",
      "Neural network found that trial country is likely to be USCA.\n",
      "\n",
      "Neural network for is trial international? output: 0.\n",
      "\n",
      "Naive Bayes model for is trial international? output: 0.\n",
      "\n",
      "Ensemble model output: {\"prediction\": [\"US\", \"CA\"], \"score\": {\"PE\": 0.07, \"XX\": 0.09, \"US\": 0.77, \"CA\": 0.53}}\n",
      "\n",
      "Searching for any mentions of simulation...\n",
      "It does not look like the authors used simulation for sample size.\n",
      "\n",
      "Splitting the document into words (tokens)...\n",
      "There were 11067 words in the document.\n",
      "\n",
      "Searching for a likely pathology...\n",
      "This looks like an HIV trial.\n",
      "\n",
      "Searching for a phase...\n",
      "This looks like a Phase 3.0 trial.\n",
      "\n",
      "Neural network thought it was a Phase 4.0 trial.\n",
      "\n",
      "Searching for a statistical analysis plan...\n",
      "It does not look like the protocol contains a statistical analysis plan.\n",
      "\n",
      "Testing top pages for SAP with document level SAP Naive Bayes model to refine SAP prediction.\n",
      "\n",
      "Document level Naive Bayes model found SAP score 1 with score 0.5196707070269995.\n",
      "\n",
      "Searching for an effect estimate...\n",
      "It does not look like the protocol contains an effect estimate.\n",
      "\n",
      "Naive Bayes arms prediction probabilities: {'1': 0.1956909344691509, '2': 0.5265524954442365, '3+': 0.277756570086613}.\n",
      "\n",
      "Spacy arms prediction probabilities: {'1': 0.9948581457138062, '2': 0.001154575264081359, '3+': 0.003987341187894344}.\n",
      "\n",
      "Searching for a number of arms...\n",
      "No explicit mention of arms found.\n",
      "\n",
      "Running Random Forest classifier for number of subjects...\n",
      "Searching for a number of subjects...\n",
      "It looks like the trial has 30 participants.\n",
      "\n",
      "Searching for the countries of investigation...\n",
      "It looks like the trial takes place in 1 country: US\n",
      "\n",
      "Neural network found that trial country is likely to be LMIC.\n",
      "\n",
      "Neural network for is trial international? output: 0.\n",
      "\n",
      "Naive Bayes model for is trial international? output: 0.\n",
      "\n",
      "Ensemble model output: {\"prediction\": [\"US\"], \"score\": {\"US\": 0.95, \"XX\": 0.0, \"FR\": 0.09, \"UG\": 0.02}}\n",
      "\n",
      "Searching for any mentions of simulation...\n",
      "It does not look like the authors used simulation for sample size.\n",
      "\n",
      "Splitting the document into words (tokens)...\n",
      "There were 49737 words in the document.\n",
      "\n",
      "Searching for a likely pathology...\n",
      "This looks like an HIV trial.\n",
      "\n",
      "Searching for a phase...\n",
      "This looks like a Phase 1.5 trial.\n",
      "\n",
      "Neural network thought it was a Phase 1.5 trial.\n",
      "\n",
      "Searching for a statistical analysis plan...\n",
      "It does not look like the protocol contains a statistical analysis plan.\n",
      "\n",
      "Testing top pages for SAP with document level SAP Naive Bayes model to refine SAP prediction.\n",
      "\n",
      "Document level Naive Bayes model found SAP score 1 with score 0.5896859191453977.\n",
      "\n",
      "Searching for an effect estimate...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/thomas/642d0db5-2c98-4156-b591-1a3572c5868c/anaconda3/envs/protocols/lib/python3.10/site-packages/pandas/util/_decorators.py:311: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified probable effect estimate.\n",
      "\n",
      "Naive Bayes arms prediction probabilities: {'1': 0.15118132734068362, '2': 0.42239348119637854, '3+': 0.42642519146293606}.\n",
      "\n",
      "Spacy arms prediction probabilities: {'1': 8.177267890596696e-12, '2': 1.6423006617832803e-14, '3+': 1.0}.\n",
      "\n",
      "Searching for a number of arms...\n",
      "No explicit mention of arms found.\n",
      "\n",
      "Running Random Forest classifier for number of subjects...\n",
      "Searching for a number of subjects...\n",
      "It looks like the trial has 12 participants.\n",
      "\n",
      "Searching for the countries of investigation...\n",
      "It looks like the trial takes place in 1 country: US\n",
      "\n",
      "Neural network found that trial country is likely to be USCA.\n",
      "\n",
      "Neural network for is trial international? output: 1.\n",
      "\n",
      "Naive Bayes model for is trial international? output: 0.\n",
      "\n",
      "Ensemble model output: {\"prediction\": [\"US\", \"XX\"], \"score\": {\"US\": 0.86, \"XX\": 0.51, \"PR\": 0.2525, \"AU\": 0.1}}\n",
      "\n",
      "Searching for any mentions of simulation...\n",
      "It does not look like the authors used simulation for sample size.\n",
      "\n",
      "Splitting the document into words (tokens)...\n",
      "There were 27459 words in the document.\n",
      "\n",
      "Searching for a likely pathology...\n",
      "This looks like an HIV trial.\n",
      "\n",
      "Searching for a phase...\n",
      "This looks like a Phase 1.0 trial.\n",
      "\n",
      "Neural network thought it was a Phase 1.0 trial.\n",
      "\n",
      "Searching for a statistical analysis plan...\n",
      "It does not look like the protocol contains a statistical analysis plan.\n",
      "\n",
      "Testing top pages for SAP with document level SAP Naive Bayes model to refine SAP prediction.\n",
      "\n",
      "Document level Naive Bayes model found SAP score 0 with score 0.40568117516592767.\n",
      "\n",
      "Searching for an effect estimate...\n",
      "Identified probable effect estimate.\n",
      "\n",
      "Naive Bayes arms prediction probabilities: {'1': 0.16357064400211996, '2': 0.46017008992258207, '3+': 0.37625926607529875}.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/thomas/642d0db5-2c98-4156-b591-1a3572c5868c/anaconda3/envs/protocols/lib/python3.10/site-packages/pandas/util/_decorators.py:311: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spacy arms prediction probabilities: {'1': 0.9709116816520691, '2': 0.026525888592004776, '3+': 0.0025623939000070095}.\n",
      "\n",
      "Searching for a number of arms...\n",
      "No explicit mention of arms found.\n",
      "\n",
      "Running Random Forest classifier for number of subjects...\n",
      "Searching for a number of subjects...\n",
      "It looks like the trial has 42 participants.\n",
      "\n",
      "Searching for the countries of investigation...\n",
      "It looks like the trial takes place in 1 country: US\n",
      "\n",
      "Neural network found that trial country is likely to be HIGH_INCOME.\n",
      "\n",
      "Neural network for is trial international? output: 1.\n",
      "\n",
      "Naive Bayes model for is trial international? output: 1.\n",
      "\n",
      "Ensemble model output: {\"prediction\": [\"US\", \"XX\", \"CA\"], \"score\": {\"US\": 0.82, \"XX\": 0.61, \"CA\": 0.24}}\n",
      "\n",
      "Searching for any mentions of simulation...\n",
      "It does not look like the authors used simulation for sample size.\n",
      "\n",
      "Splitting the document into words (tokens)...\n",
      "There were 20099 words in the document.\n",
      "\n",
      "Searching for a likely pathology...\n",
      "This looks like an HIV trial.\n",
      "\n",
      "Searching for a phase...\n",
      "This looks like a Phase 0.0 trial.\n",
      "\n",
      "Neural network thought it was a Phase 2.0 trial.\n",
      "\n",
      "Searching for a statistical analysis plan...\n",
      "It does not look like the protocol contains a statistical analysis plan.\n",
      "\n",
      "Testing top pages for SAP with document level SAP Naive Bayes model to refine SAP prediction.\n",
      "\n",
      "Document level Naive Bayes model found SAP score 1 with score 0.583919920182189.\n",
      "\n",
      "Searching for an effect estimate...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/thomas/642d0db5-2c98-4156-b591-1a3572c5868c/anaconda3/envs/protocols/lib/python3.10/site-packages/pandas/util/_decorators.py:311: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified probable effect estimate.\n",
      "\n",
      "Naive Bayes arms prediction probabilities: {'1': 0.19137695503086102, '2': 0.6272001237812409, '3+': 0.18142292118789793}.\n",
      "\n",
      "Spacy arms prediction probabilities: {'1': 0.9835612773895264, '2': 0.013964853249490261, '3+': 0.002473793923854828}.\n",
      "\n",
      "Searching for a number of arms...\n",
      "It looks like the trial has 2 arm(s).\n",
      "\n",
      "The NB prediction and the rule based prediction match!\n",
      "Running Random Forest classifier for number of subjects...\n",
      "Searching for a number of subjects...\n",
      "It looks like the trial has 90 participants.\n",
      "\n",
      "Searching for the countries of investigation...\n",
      "It looks like the trial takes place in 1 country: US\n",
      "\n",
      "Neural network found that trial country is likely to be USCA.\n",
      "\n",
      "Neural network for is trial international? output: 0.\n",
      "\n",
      "Naive Bayes model for is trial international? output: 0.\n",
      "\n",
      "Ensemble model output: {\"prediction\": [\"US\"], \"score\": {\"US\": 0.88, \"XX\": 0.04, \"JP\": 0.03}}\n",
      "\n",
      "Searching for any mentions of simulation...\n",
      "It does not look like the authors used simulation for sample size.\n",
      "\n",
      "Splitting the document into words (tokens)...\n",
      "There were 31712 words in the document.\n",
      "\n",
      "Searching for a likely pathology...\n",
      "This looks like an HIV trial.\n",
      "\n",
      "Searching for a phase...\n",
      "This looks like a Phase 3.0 trial.\n",
      "\n",
      "Neural network thought it was a Phase 2.0 trial.\n",
      "\n",
      "Searching for a statistical analysis plan...\n",
      "It does not look like the protocol contains a statistical analysis plan.\n",
      "\n",
      "Testing top pages for SAP with document level SAP Naive Bayes model to refine SAP prediction.\n",
      "\n",
      "Document level Naive Bayes model found SAP score 0 with score 0.32866584027927404.\n",
      "\n",
      "Searching for an effect estimate...\n",
      "It does not look like the protocol contains an effect estimate.\n",
      "\n",
      "Naive Bayes arms prediction probabilities: {'1': 0.18207755024886516, '2': 0.44683627962772293, '3+': 0.37108617012341244}.\n",
      "\n",
      "Spacy arms prediction probabilities: {'1': 0.9998593330383301, '2': 1.639016589116693e-09, '3+': 0.00014065462164580822}.\n",
      "\n",
      "Searching for a number of arms...\n",
      "It looks like the trial has 2 arm(s).\n",
      "\n",
      "The NB prediction and the rule based prediction match!\n",
      "Running Random Forest classifier for number of subjects...\n",
      "Searching for a number of subjects...\n",
      "It looks like the trial has 100 participants.\n",
      "\n",
      "Searching for the countries of investigation...\n",
      "It looks like the trial takes place in 2 countries: US,TW\n",
      "\n",
      "Neural network found that trial country is likely to be USCA.\n",
      "\n",
      "Neural network for is trial international? output: 1.\n",
      "\n",
      "Naive Bayes model for is trial international? output: 1.\n",
      "\n",
      "Ensemble model output: {\"prediction\": [\"US\", \"XX\", \"TW\"], \"score\": {\"TW\": 0.36039682539682544, \"XX\": 0.3722888283378747, \"US\": 0.71}}\n",
      "\n",
      "Searching for any mentions of simulation...\n",
      "It does not look like the authors used simulation for sample size.\n",
      "\n",
      "Splitting the document into words (tokens)...\n",
      "There were 18153 words in the document.\n",
      "\n",
      "Searching for a likely pathology...\n",
      "This looks like an HIV trial.\n",
      "\n",
      "Searching for a phase...\n",
      "This looks like a Phase 1.0 trial.\n",
      "\n",
      "Neural network thought it was a Phase 1.0 trial.\n",
      "\n",
      "Searching for a statistical analysis plan...\n",
      "It does not look like the protocol contains a statistical analysis plan.\n",
      "\n",
      "Testing top pages for SAP with document level SAP Naive Bayes model to refine SAP prediction.\n",
      "\n",
      "Document level Naive Bayes model found SAP score 1 with score 0.5097078212222643.\n",
      "\n",
      "Searching for an effect estimate...\n",
      "It does not look like the protocol contains an effect estimate.\n",
      "\n",
      "Naive Bayes arms prediction probabilities: {'1': 0.23550091794530237, '2': 0.47037496124775424, '3+': 0.2941241208069436}.\n",
      "\n",
      "Spacy arms prediction probabilities: {'1': 0.9995941519737244, '2': 0.00038036261685192585, '3+': 2.5501209165668115e-05}.\n",
      "\n",
      "Searching for a number of arms...\n",
      "No explicit mention of arms found.\n",
      "\n",
      "Running Random Forest classifier for number of subjects...\n",
      "Searching for a number of subjects...\n",
      "It looks like the trial has 20 participants.\n",
      "\n",
      "Searching for the countries of investigation...\n",
      "No country was found.\n",
      "Neural network found that trial country is likely to be USCA.\n",
      "\n",
      "Neural network for is trial international? output: 0.\n",
      "\n",
      "Naive Bayes model for is trial international? output: 0.\n",
      "\n",
      "Ensemble model output: {\"prediction\": [\"US\"], \"score\": {}}\n",
      "\n",
      "Searching for any mentions of simulation...\n",
      "It does not look like the authors used simulation for sample size.\n",
      "\n",
      "Splitting the document into words (tokens)...\n",
      "There were 29488 words in the document.\n",
      "\n",
      "Searching for a likely pathology...\n",
      "This looks like an HIV trial.\n",
      "\n",
      "Searching for a phase...\n",
      "This looks like a Phase 1.5 trial.\n",
      "\n",
      "Neural network thought it was a Phase 2.0 trial.\n",
      "\n",
      "Searching for a statistical analysis plan...\n",
      "It does not look like the protocol contains a statistical analysis plan.\n",
      "\n",
      "Testing top pages for SAP with document level SAP Naive Bayes model to refine SAP prediction.\n",
      "\n",
      "Document level Naive Bayes model found SAP score 1 with score 0.6255490244048496.\n",
      "\n",
      "Searching for an effect estimate...\n",
      "It does not look like the protocol contains an effect estimate.\n",
      "\n",
      "Naive Bayes arms prediction probabilities: {'1': 0.4890112440198192, '2': 0.31692064376176704, '3+': 0.19406811221841466}.\n",
      "\n",
      "Spacy arms prediction probabilities: {'1': 0.9505137801170349, '2': 0.0047520361840724945, '3+': 0.04473429173231125}.\n",
      "\n",
      "Searching for a number of arms...\n",
      "No explicit mention of arms found.\n",
      "\n",
      "Running Random Forest classifier for number of subjects...\n",
      "Searching for a number of subjects...\n",
      "It looks like the trial has 17 participants.\n",
      "\n",
      "Searching for the countries of investigation...\n",
      "It looks like the trial takes place in 1 country: US\n",
      "\n",
      "Neural network found that trial country is likely to be USCA.\n",
      "\n",
      "Neural network for is trial international? output: 0.\n",
      "\n",
      "Naive Bayes model for is trial international? output: 0.\n",
      "\n",
      "Ensemble model output: {\"prediction\": [\"US\"], \"score\": {\"US\": 0.93, \"XX\": 0.0, \"CA\": 0.4047619047619048}}\n",
      "\n",
      "Searching for any mentions of simulation...\n",
      "It does not look like the authors used simulation for sample size.\n",
      "\n",
      "Splitting the document into words (tokens)...\n",
      "There were 13346 words in the document.\n",
      "\n",
      "Searching for a likely pathology...\n",
      "This looks like an HIV trial.\n",
      "\n",
      "Searching for a phase...\n",
      "This looks like a Phase 2.0 trial.\n",
      "\n",
      "Neural network thought it was a Phase 2.0 trial.\n",
      "\n",
      "Searching for a statistical analysis plan...\n",
      "It does not look like the protocol contains a statistical analysis plan.\n",
      "\n",
      "Testing top pages for SAP with document level SAP Naive Bayes model to refine SAP prediction.\n",
      "\n",
      "Document level Naive Bayes model found SAP score 1 with score 0.7624503665033614.\n",
      "\n",
      "Searching for an effect estimate...\n",
      "Identified probable effect estimate.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/thomas/642d0db5-2c98-4156-b591-1a3572c5868c/anaconda3/envs/protocols/lib/python3.10/site-packages/pandas/util/_decorators.py:311: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes arms prediction probabilities: {'1': 0.3463099179685934, '2': 0.4249519942183664, '3+': 0.2287380878130412}.\n",
      "\n",
      "Spacy arms prediction probabilities: {'1': 0.9584068059921265, '2': 0.04113499075174332, '3+': 0.000458122871350497}.\n",
      "\n",
      "Searching for a number of arms...\n",
      "No explicit mention of arms found.\n",
      "\n",
      "Running Random Forest classifier for number of subjects...\n",
      "Searching for a number of subjects...\n",
      "It looks like the trial has 12 participants.\n",
      "\n",
      "Searching for the countries of investigation...\n",
      "It looks like the trial takes place in 1 country: US\n",
      "\n",
      "Neural network found that trial country is likely to be USCA.\n",
      "\n",
      "Neural network for is trial international? output: 0.\n",
      "\n",
      "Naive Bayes model for is trial international? output: 0.\n",
      "\n",
      "Ensemble model output: {\"prediction\": [\"US\"], \"score\": {\"US\": 0.96, \"XX\": 0.04, \"CN\": 0.03, \"ES\": 0.0}}\n",
      "\n",
      "Searching for any mentions of simulation...\n",
      "It does not look like the authors used simulation for sample size.\n",
      "\n",
      "Splitting the document into words (tokens)...\n",
      "There were 34314 words in the document.\n",
      "\n",
      "Searching for a likely pathology...\n",
      "This looks like an HIV trial.\n",
      "\n",
      "Searching for a phase...\n",
      "This looks like a Phase 1.0 trial.\n",
      "\n",
      "Neural network thought it was a Phase 1.0 trial.\n",
      "\n",
      "Searching for a statistical analysis plan...\n",
      "It does not look like the protocol contains a statistical analysis plan.\n",
      "\n",
      "Testing top pages for SAP with document level SAP Naive Bayes model to refine SAP prediction.\n",
      "\n",
      "Document level Naive Bayes model found SAP score 0 with score 0.3878602042747384.\n",
      "\n",
      "Searching for an effect estimate...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/thomas/642d0db5-2c98-4156-b591-1a3572c5868c/anaconda3/envs/protocols/lib/python3.10/site-packages/pandas/util/_decorators.py:311: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified probable effect estimate.\n",
      "\n",
      "Naive Bayes arms prediction probabilities: {'1': 0.162217547077688, '2': 0.46003542613266685, '3+': 0.3777470267896435}.\n",
      "\n",
      "Spacy arms prediction probabilities: {'1': 0.49293360114097595, '2': 0.00897599384188652, '3+': 0.49809032678604126}.\n",
      "\n",
      "Searching for a number of arms...\n",
      "No explicit mention of arms found.\n",
      "\n",
      "Running Random Forest classifier for number of subjects...\n",
      "Searching for a number of subjects...\n",
      "It looks like the trial has 30 participants.\n",
      "\n",
      "Searching for the countries of investigation...\n",
      "It looks like the trial takes place in 2 countries: JE,US\n",
      "\n",
      "Neural network found that trial country is likely to be HIGH_INCOME.\n",
      "\n",
      "Neural network for is trial international? output: 1.\n",
      "\n",
      "Naive Bayes model for is trial international? output: 1.\n",
      "\n",
      "Ensemble model output: {\"prediction\": [\"US\", \"XX\", \"JE\", \"CA\", \"HT\"], \"score\": {\"US\": 0.63, \"XX\": 0.48323710419994365, \"JE\": 0.32, \"HT\": 0.14, \"CA\": 0.27}}\n",
      "\n",
      "Searching for any mentions of simulation...\n",
      "It does not look like the authors used simulation for sample size.\n",
      "\n",
      "Splitting the document into words (tokens)...\n",
      "There were 45645 words in the document.\n",
      "\n",
      "Searching for a likely pathology...\n",
      "This looks like a TB trial.\n",
      "\n",
      "Searching for a phase...\n",
      "This looks like a Phase 3.0 trial.\n",
      "\n",
      "Neural network thought it was a Phase 2.0 trial.\n",
      "\n",
      "Searching for a statistical analysis plan...\n",
      "It does not look like the protocol contains a statistical analysis plan.\n",
      "\n",
      "Testing top pages for SAP with document level SAP Naive Bayes model to refine SAP prediction.\n",
      "\n",
      "Document level Naive Bayes model found SAP score 0 with score 0.43654901171198807.\n",
      "\n",
      "Searching for an effect estimate...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/thomas/642d0db5-2c98-4156-b591-1a3572c5868c/anaconda3/envs/protocols/lib/python3.10/site-packages/pandas/util/_decorators.py:311: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified probable effect estimate.\n",
      "\n",
      "Naive Bayes arms prediction probabilities: {'1': 0.12098348807626519, '2': 0.5536303314544273, '3+': 0.325386180469307}.\n",
      "\n",
      "Spacy arms prediction probabilities: {'1': 1.8780308863597384e-08, '2': 0.9986351132392883, '3+': 0.0013648311141878366}.\n",
      "\n",
      "Searching for a number of arms...\n",
      "No explicit mention of arms found.\n",
      "\n",
      "Running Random Forest classifier for number of subjects...\n",
      "Searching for a number of subjects...\n",
      "It looks like the trial has 1500 participants.\n",
      "\n",
      "Searching for the countries of investigation...\n",
      "It looks like the trial takes place in 1 country: GB\n",
      "\n",
      "Neural network found that trial country is likely to be USCA.\n",
      "\n",
      "Neural network for is trial international? output: 1.\n",
      "\n",
      "Naive Bayes model for is trial international? output: 1.\n",
      "\n",
      "Ensemble model output: {\"prediction\": [\"US\", \"CA\", \"GB\", \"XX\", \"CH\"], \"score\": {\"GB\": 0.33, \"XX\": 0.32228882833787464, \"US\": 0.54, \"CA\": 0.425, \"UG\": 0.08206349206349206, \"BR\": 0.07706349206349207, \"ES\": 0.04285000891742465, \"CN\": 0.007850008917424647, \"IN\": 0.007850008917424647, \"KE\": 0.007850008917424647, \"MY\": 0.007850008917424647, \"MX\": 0.007850008917424647, \"TZ\": 0.007850008917424647, \"TH\": 0.007850008917424647, \"ZM\": 0.007850008917424647, \"BD\": 0.03918334225075798, \"NL\": 0.05118334225075798, \"CH\": 0.10539682539682539}}\n",
      "\n",
      "Searching for any mentions of simulation...\n",
      "It does not look like the authors used simulation for sample size.\n",
      "\n",
      "Splitting the document into words (tokens)...\n",
      "There were 23220 words in the document.\n",
      "\n",
      "Searching for a likely pathology...\n",
      "This looks like a TB trial.\n",
      "\n",
      "Searching for a phase...\n",
      "This looks like a Phase 1.0 trial.\n",
      "\n",
      "Neural network thought it was a Phase 4.0 trial.\n",
      "\n",
      "Searching for a statistical analysis plan...\n",
      "It does not look like the protocol contains a statistical analysis plan.\n",
      "\n",
      "Testing top pages for SAP with document level SAP Naive Bayes model to refine SAP prediction.\n",
      "\n",
      "Document level Naive Bayes model found SAP score 1 with score 0.5822849728592837.\n",
      "\n",
      "Searching for an effect estimate...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/thomas/642d0db5-2c98-4156-b591-1a3572c5868c/anaconda3/envs/protocols/lib/python3.10/site-packages/pandas/util/_decorators.py:311: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified probable effect estimate.\n",
      "\n",
      "Naive Bayes arms prediction probabilities: {'1': 0.1606261920119335, '2': 0.5801105175133234, '3+': 0.25926329047474334}.\n",
      "\n",
      "Spacy arms prediction probabilities: {'1': 2.3474545741919428e-05, '2': 0.9978971481323242, '3+': 0.0020793399307876825}.\n",
      "\n",
      "Searching for a number of arms...\n",
      "No explicit mention of arms found.\n",
      "\n",
      "Running Random Forest classifier for number of subjects...\n",
      "Searching for a number of subjects...\n",
      "It looks like the trial has 1000 participants.\n",
      "\n",
      "Searching for the countries of investigation...\n",
      "It looks like the trial takes place in 1 country: BE\n",
      "\n",
      "Neural network found that trial country is likely to be LMIC.\n",
      "\n",
      "Neural network for is trial international? output: 0.\n",
      "\n",
      "Naive Bayes model for is trial international? output: 0.\n",
      "\n",
      "Ensemble model output: {\"prediction\": [\"BE\", \"BD\"], \"score\": {\"BE\": 0.88, \"XX\": 0.07, \"BD\": 0.8036666666666668, \"DE\": 0.25, \"BR\": 0.18, \"JP\": 0.1675, \"TW\": 0.03, \"NL\": 0.03, \"ZA\": 0.19, \"GB\": 0.19, \"NP\": 0.19, \"BO\": 0.21, \"CH\": 0.05, \"UG\": 0.21, \"FI\": 0.03, \"IT\": 0.03, \"HK\": 0.03, \"US\": 0.31, \"KR\": 0.03}}\n",
      "\n",
      "Searching for any mentions of simulation...\n",
      "It does not look like the authors used simulation for sample size.\n",
      "\n",
      "Splitting the document into words (tokens)...\n",
      "There were 45947 words in the document.\n",
      "\n",
      "Searching for a likely pathology...\n",
      "This looks like a TB trial.\n",
      "\n",
      "Searching for a phase...\n",
      "This looks like a Phase 2.0 trial.\n",
      "\n",
      "Neural network thought it was a Phase 2.0 trial.\n",
      "\n",
      "Searching for a statistical analysis plan...\n",
      "It does not look like the protocol contains a statistical analysis plan.\n",
      "\n",
      "Testing top pages for SAP with document level SAP Naive Bayes model to refine SAP prediction.\n",
      "\n",
      "Document level Naive Bayes model found SAP score 1 with score 0.5822153080393969.\n",
      "\n",
      "Searching for an effect estimate...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/thomas/642d0db5-2c98-4156-b591-1a3572c5868c/anaconda3/envs/protocols/lib/python3.10/site-packages/pandas/util/_decorators.py:311: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified probable effect estimate.\n",
      "\n",
      "Naive Bayes arms prediction probabilities: {'1': 0.14320828468363228, '2': 0.5435733601266712, '3+': 0.31321835518969543}.\n",
      "\n",
      "Spacy arms prediction probabilities: {'1': 9.648121711280933e-12, '2': 0.9996166229248047, '3+': 0.0003833440423477441}.\n",
      "\n",
      "Searching for a number of arms...\n",
      "It looks like the trial has 3 arm(s).\n",
      "\n",
      "Running Random Forest classifier for number of subjects...\n",
      "Searching for a number of subjects...\n",
      "It looks like the trial has 84 participants.\n",
      "\n",
      "Searching for the countries of investigation...\n",
      "It looks like the trial takes place in 1 country: US\n",
      "\n",
      "Neural network found that trial country is likely to be USCA.\n",
      "\n",
      "Neural network for is trial international? output: 0.\n",
      "\n",
      "Naive Bayes model for is trial international? output: 0.\n",
      "\n",
      "Ensemble model output: {\"prediction\": [\"US\", \"ZA\", \"XX\"], \"score\": {\"US\": 0.9, \"XX\": 0.7, \"ZA\": 0.72, \"CO\": 0.31, \"SE\": 0.255, \"MW\": 0.30916666666666665, \"KE\": 0.30916666666666665, \"GB\": 0.33, \"JP\": 0.15, \"CN\": 0.18, \"PE\": 0.03, \"KR\": 0.16, \"PH\": 0.03, \"EG\": 0.04, \"BW\": 0.2, \"CH\": 0.14, \"IN\": 0.19, \"BD\": 0.04, \"NE\": 0.04, \"CM\": 0.04, \"RU\": 0.03}}\n",
      "\n",
      "Searching for any mentions of simulation...\n",
      "The authors probably used simulation for sample size.\n",
      "\n",
      "Splitting the document into words (tokens)...\n",
      "There were 52315 words in the document.\n",
      "\n",
      "Searching for a likely pathology...\n",
      "This looks like a TB trial.\n",
      "\n",
      "Searching for a phase...\n",
      "This looks like a Phase 2.0 trial.\n",
      "\n",
      "Neural network thought it was a Phase 2.0 trial.\n",
      "\n",
      "Searching for a statistical analysis plan...\n",
      "It does not look like the protocol contains a statistical analysis plan.\n",
      "\n",
      "Testing top pages for SAP with document level SAP Naive Bayes model to refine SAP prediction.\n",
      "\n",
      "Document level Naive Bayes model found SAP score 0 with score 0.4248145125949151.\n",
      "\n",
      "Searching for an effect estimate...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/thomas/642d0db5-2c98-4156-b591-1a3572c5868c/anaconda3/envs/protocols/lib/python3.10/site-packages/pandas/util/_decorators.py:311: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified probable effect estimate.\n",
      "\n",
      "Naive Bayes arms prediction probabilities: {'1': 0.12485820690180549, '2': 0.5078040175363748, '3+': 0.36733777556181874}.\n",
      "\n",
      "Spacy arms prediction probabilities: {'1': 1.773104355092267e-23, '2': 0.00025447257212363183, '3+': 0.9997455477714539}.\n",
      "\n",
      "Searching for a number of arms...\n",
      "No explicit mention of arms found.\n",
      "\n",
      "Running Random Forest classifier for number of subjects...\n",
      "Searching for a number of subjects...\n",
      "It looks like the trial has 240 participants.\n",
      "\n",
      "Searching for the countries of investigation...\n",
      "It looks like the trial takes place in 1 country: ZA\n",
      "\n",
      "Neural network found that trial country is likely to be USCA.\n",
      "\n",
      "Neural network for is trial international? output: 1.\n",
      "\n",
      "Naive Bayes model for is trial international? output: 1.\n",
      "\n",
      "Ensemble model output: {\"prediction\": [\"US\", \"XX\", \"ZA\", \"MX\"], \"score\": {\"ZA\": 0.38, \"XX\": 0.46228882833787466, \"US\": 0.55, \"MX\": 0.1370166755840913}}\n",
      "\n",
      "Searching for any mentions of simulation...\n",
      "It does not look like the authors used simulation for sample size.\n",
      "\n",
      "Splitting the document into words (tokens)...\n",
      "There were 87944 words in the document.\n",
      "\n",
      "Searching for a likely pathology...\n",
      "This looks like a TB trial.\n",
      "\n",
      "Searching for a phase...\n",
      "This looks like a Phase 3.0 trial.\n",
      "\n",
      "Neural network thought it was a Phase 3.0 trial.\n",
      "\n",
      "Searching for a statistical analysis plan...\n",
      "It looks like the authors have included their statistical analysis plan in the protocol.\n",
      "\n",
      "Testing top pages for SAP with document level SAP Naive Bayes model to refine SAP prediction.\n",
      "\n",
      "Document level Naive Bayes model found SAP score 1 with score 0.5043774484012308.\n",
      "\n",
      "Searching for an effect estimate...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/thomas/642d0db5-2c98-4156-b591-1a3572c5868c/anaconda3/envs/protocols/lib/python3.10/site-packages/pandas/util/_decorators.py:311: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified probable effect estimate.\n",
      "\n",
      "Naive Bayes arms prediction probabilities: {'1': 0.08751904288587753, '2': 0.6205856619163611, '3+': 0.29189529519775914}.\n",
      "\n",
      "Spacy arms prediction probabilities: {'1': 0.9999592304229736, '2': 4.0807433833833784e-05, '3+': 2.2045772325729462e-12}.\n",
      "\n",
      "Searching for a number of arms...\n",
      "No explicit mention of arms found.\n",
      "\n",
      "Running Random Forest classifier for number of subjects...\n",
      "Searching for a number of subjects...\n",
      "It looks like the trial has 90 participants.\n",
      "\n",
      "Searching for the countries of investigation...\n",
      "It looks like the trial takes place in 1 country: US\n",
      "\n",
      "Neural network found that trial country is likely to be USCA.\n",
      "\n",
      "Neural network for is trial international? output: 1.\n",
      "\n",
      "Naive Bayes model for is trial international? output: 0.\n",
      "\n",
      "Ensemble model output: {\"prediction\": [\"US\"], \"score\": {\"US\": 0.77, \"XX\": 0.23, \"HK\": 0.32, \"CN\": 0.18, \"ZA\": 0.33, \"VN\": 0.34, \"FR\": 0.32, \"ES\": 0.32, \"ZW\": 0.18, \"KE\": 0.11, \"PE\": 0.11, \"UG\": 0.11, \"SG\": 0.2, \"BE\": 0.13}}\n",
      "\n",
      "Searching for any mentions of simulation...\n",
      "The authors probably used simulation for sample size.\n",
      "\n",
      "Splitting the document into words (tokens)...\n",
      "There were 21885 words in the document.\n",
      "\n",
      "Searching for a likely pathology...\n",
      "This looks like a TB trial.\n",
      "\n",
      "Searching for a phase...\n",
      "This looks like a Phase 2.0 trial.\n",
      "\n",
      "Neural network thought it was a Phase 4.0 trial.\n",
      "\n",
      "Searching for a statistical analysis plan...\n",
      "It does not look like the protocol contains a statistical analysis plan.\n",
      "\n",
      "Testing top pages for SAP with document level SAP Naive Bayes model to refine SAP prediction.\n",
      "\n",
      "Document level Naive Bayes model found SAP score 1 with score 0.6278246211404404.\n",
      "\n",
      "Searching for an effect estimate...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/thomas/642d0db5-2c98-4156-b591-1a3572c5868c/anaconda3/envs/protocols/lib/python3.10/site-packages/pandas/util/_decorators.py:311: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified probable effect estimate.\n",
      "\n",
      "Naive Bayes arms prediction probabilities: {'1': 0.12629555371977186, '2': 0.593418011984293, '3+': 0.28028643429593475}.\n",
      "\n",
      "Spacy arms prediction probabilities: {'1': 0.0014953858917579055, '2': 0.953068196773529, '3+': 0.04543643444776535}.\n",
      "\n",
      "Searching for a number of arms...\n",
      "No explicit mention of arms found.\n",
      "\n",
      "Running Random Forest classifier for number of subjects...\n",
      "Searching for a number of subjects...\n",
      "It looks like the trial has 330 participants.\n",
      "\n",
      "Searching for the countries of investigation...\n",
      "It looks like the trial takes place in 1 country: ZA\n",
      "\n",
      "Neural network found that trial country is likely to be USCA.\n",
      "\n",
      "Neural network for is trial international? output: 0.\n",
      "\n",
      "Naive Bayes model for is trial international? output: 0.\n",
      "\n",
      "Ensemble model output: {\"prediction\": [\"ZA\", \"US\"], \"score\": {\"ZA\": 0.91, \"XX\": 0.0, \"CO\": 0.12, \"UG\": 0.07, \"GE\": 0.02, \"TZ\": 0.02, \"KE\": 0.04, \"US\": 0.69, \"CH\": 0.02, \"BW\": 0.04}}\n",
      "\n",
      "Searching for any mentions of simulation...\n",
      "The authors probably used simulation for sample size.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_cond = []\n",
    "pred_phase = []\n",
    "pred_arms = []\n",
    "pred_sap = []\n",
    "pred_subjects = []\n",
    "pred_sim = []\n",
    "pred_effect = []\n",
    "pred_countries = []\n",
    "\n",
    "for idx in range(len(df_testing)):\n",
    "    tokenised_pages, condition_to_pages, phase_to_pages, sap_to_pages, \\\n",
    "               effect_estimate_to_pages, num_subjects_to_pages,\\\n",
    "    num_arms_to_pages, country_to_pages, simulation_to_pages = master_processor.process_protocol(df_testing[\"pages\"].iloc[idx])\n",
    "    pred_cond.append(condition_to_pages[\"prediction\"])\n",
    "    pred_phase.append(phase_to_pages[\"prediction\"])\n",
    "    pred_arms.append(num_arms_to_pages[\"prediction\"])\n",
    "    pred_sap.append(sap_to_pages[\"prediction\"])\n",
    "    pred_subjects.append(num_subjects_to_pages[\"prediction\"])    \n",
    "    pred_sim.append(simulation_to_pages[\"prediction\"])    \n",
    "    pred_effect.append(effect_estimate_to_pages[\"prediction\"])        \n",
    "    pred_countries.append(country_to_pages[\"prediction\"])        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d674ca3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_testing.insert(df_testing.columns.get_loc(\"Indication\") + 1, \"AI_Indication_v2\", pred_cond)\n",
    "df_testing.insert(df_testing.columns.get_loc(\"AI_phase\") + 1, \"AI_phase_v2\", pred_phase)\n",
    "df_testing.insert(df_testing.columns.get_loc(\"Rev_arms\") + 1, \"AI_arms_v2\", pred_arms)\n",
    "df_testing.insert(df_testing.columns.get_loc(\"AI_SAP\") + 1, \"AI_SAP_v2\", pred_sap)\n",
    "df_testing.insert(df_testing.columns.get_loc(\"AI_N\") + 1, \"AI_N_v2\", pred_subjects)\n",
    "df_testing.insert(df_testing.columns.get_loc(\"AI_effect\") + 1, \"AI_effect_v2\", pred_effect)\n",
    "df_testing.insert(df_testing.columns.get_loc(\"AI_sim\") + 1, \"AI_sim_v2\", pred_sim)\n",
    "df_testing.insert(df_testing.columns.get_loc(\"Rev_countries\") + 1, \"AI_countries_v2\", [\",\".join(sorted(set(c))) for c in pred_countries])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7ad8dfe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "920bf1df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phase accuracy v1: 0.5\n",
      "Phase accuracy v2: 0.6875\n"
     ]
    }
   ],
   "source": [
    "phase_map = {\"1/2\":\"0.5\"}\n",
    "accuracies['AI_phase'] = accuracy_score(df_testing.Rev_phase.apply(str).apply(lambda x : phase_map.get(x, x)), df_testing.AI_phase.apply(str))\n",
    "\n",
    "accuracies['AI_phase_v2'] = accuracy_score(df_testing.Rev_phase.apply(str), df_testing.AI_phase_v2.apply(str).apply(lambda x : re.sub(r'\\.0', '', x)))\n",
    "\n",
    "print (f\"Phase accuracy v1: {accuracies['AI_phase']}\")\n",
    "print (f\"Phase accuracy v2: {accuracies['AI_phase_v2']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "157860ef",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AI_effect</th>\n",
       "      <th>Rev_effect</th>\n",
       "      <th>AI_effect_v2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yes</td>\n",
       "      <td>yes Sec. 9.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>no</td>\n",
       "      <td>yes Sec. 9.4.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>no</td>\n",
       "      <td>yes Sec. 8.1ff</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yes</td>\n",
       "      <td>yes Sec. 9.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>no</td>\n",
       "      <td>yes Sec. 9.8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>no</td>\n",
       "      <td>yes Sec. 13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>no</td>\n",
       "      <td>yes Sec. 8.4.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>no</td>\n",
       "      <td>yes Sec. 8.1ff</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>yes</td>\n",
       "      <td>yes Sec. 8.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>no</td>\n",
       "      <td>yes Sec. 8.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>yes</td>\n",
       "      <td>yes Sec. 9.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>yes</td>\n",
       "      <td>yes Sec. 8.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>yes</td>\n",
       "      <td>yes Sec. 13.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>yes</td>\n",
       "      <td>yes Sec. 9.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AI_effect      Rev_effect  AI_effect_v2\n",
       "0        yes    yes Sec. 9.3             1\n",
       "1         no              no             0\n",
       "2         no  yes Sec. 9.4.2             1\n",
       "3         no  yes Sec. 8.1ff             1\n",
       "4        yes    yes Sec. 9.4             1\n",
       "5         no    yes Sec. 9.8             0\n",
       "6         no     yes Sec. 13             0\n",
       "7         no              no             0\n",
       "8         no  yes Sec. 8.4.1             1\n",
       "9         no  yes Sec. 8.1ff             1\n",
       "10       yes    yes Sec. 8.3             1\n",
       "11        no    yes Sec. 8.4             1\n",
       "12       yes    yes Sec. 9.4             1\n",
       "13       yes    yes Sec. 8.2             1\n",
       "14       yes   yes Sec. 13.6             1\n",
       "15       yes    yes Sec. 9.1             1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_testing[[\"AI_effect\", \"Rev_effect\", \"AI_effect_v2\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a3a83524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effect accuracy v1: 0.5625\n",
      "Effect accuracy v2: 0.875\n"
     ]
    }
   ],
   "source": [
    "accuracies['AI_effect'] = accuracy_score(df_testing.Rev_effect.str.contains(\"yes\").apply(int), df_testing.AI_effect.str.contains(\"yes\").apply(int))\n",
    "accuracies['AI_effect_v2'] = accuracy_score(df_testing.Rev_effect.str.contains(\"yes\").apply(int), df_testing.AI_effect_v2)\n",
    "\n",
    "print (f\"Effect accuracy v1: {accuracies['AI_effect']}\")\n",
    "print (f\"Effect accuracy v2: {accuracies['AI_effect_v2']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3a7bd910",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_sap_gt = df_testing.Rev_SAP.apply(lambda x : int(float(re.sub(r'p.+', '', x)) > 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "69be5a01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AI_SAP</th>\n",
       "      <th>Rev_SAP</th>\n",
       "      <th>AI_SAP_v2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>no</td>\n",
       "      <td>3pp in prot</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>no</td>\n",
       "      <td>0.5p in prot</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>no</td>\n",
       "      <td>9pp in prot</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>yes</td>\n",
       "      <td>4pp in prot</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>no</td>\n",
       "      <td>2pp in prot</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>no</td>\n",
       "      <td>3pp in prot</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>no</td>\n",
       "      <td>2pp in prot</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>no</td>\n",
       "      <td>2pp in prot</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>no</td>\n",
       "      <td>1p in prot</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>no</td>\n",
       "      <td>1p in prot</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>no</td>\n",
       "      <td>4pp in prot</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>no</td>\n",
       "      <td>2pp in prot</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>no</td>\n",
       "      <td>8pp in prot</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>no</td>\n",
       "      <td>3pp in prot</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>yes</td>\n",
       "      <td>3pp in prot</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>no</td>\n",
       "      <td>2pp in prot</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AI_SAP       Rev_SAP  AI_SAP_v2\n",
       "0      no   3pp in prot          1\n",
       "1      no  0.5p in prot          1\n",
       "2      no   9pp in prot          1\n",
       "3     yes   4pp in prot          0\n",
       "4      no   2pp in prot          1\n",
       "5      no   3pp in prot          0\n",
       "6      no   2pp in prot          1\n",
       "7      no   2pp in prot          1\n",
       "8      no    1p in prot          1\n",
       "9      no    1p in prot          0\n",
       "10     no   4pp in prot          0\n",
       "11     no   2pp in prot          1\n",
       "12     no   8pp in prot          1\n",
       "13     no   3pp in prot          0\n",
       "14    yes   3pp in prot          1\n",
       "15     no   2pp in prot          1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_testing[[\"AI_SAP\", \"Rev_SAP\", \"AI_SAP_v2\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "616cc0a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAP accuracy v1: 0.3125\n",
      "SAP accuracy v2: 0.625\n"
     ]
    }
   ],
   "source": [
    "accuracies['AI_SAP'] = accuracy_score(clean_sap_gt, df_testing.AI_SAP.map({\"yes\":1,\"no\":0}))\n",
    "accuracies['AI_SAP_v2'] = accuracy_score(clean_sap_gt, df_testing.AI_SAP_v2)\n",
    "\n",
    "print (f\"SAP accuracy v1: {accuracies['AI_SAP']}\")\n",
    "print (f\"SAP accuracy v2: {accuracies['AI_SAP_v2']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9bf8d1d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AI_N</th>\n",
       "      <th>Rev_N</th>\n",
       "      <th>AI_N_v2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>51</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>59</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90</td>\n",
       "      <td>89</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100</td>\n",
       "      <td>79</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>52</td>\n",
       "      <td>26</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>49</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>450</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>900</td>\n",
       "      <td>24</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1200</td>\n",
       "      <td>284</td>\n",
       "      <td>1500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>500</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>84</td>\n",
       "      <td>84</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>240</td>\n",
       "      <td>240</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>90</td>\n",
       "      <td>2500</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>330</td>\n",
       "      <td>330</td>\n",
       "      <td>330</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    AI_N  Rev_N  AI_N_v2\n",
       "0     50     51       50\n",
       "1     44     30       30\n",
       "2     60     59       12\n",
       "3     42     42       42\n",
       "4     90     89       90\n",
       "5    100     79      100\n",
       "6     52     26       20\n",
       "7     49     17       17\n",
       "8    450      5       12\n",
       "9    900     24       30\n",
       "10  1200    284     1500\n",
       "11   500   1000     1000\n",
       "12    84     84       84\n",
       "13   240    240      240\n",
       "14    90   2500       90\n",
       "15   330    330      330"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_testing[[\"AI_N\", \"Rev_N\", \"AI_N_v2\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a7945e84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample size accuracy v1: 0.25\n",
      "Sample size accuracy v2: 0.4375\n"
     ]
    }
   ],
   "source": [
    "accuracies['AI_N'] = accuracy_score(df_testing.Rev_N, df_testing.AI_N)\n",
    "accuracies['AI_N_v2'] = accuracy_score(df_testing.Rev_N, df_testing.AI_N_v2.apply(int))\n",
    "\n",
    "print (f\"Sample size accuracy v1: {accuracies['AI_N']}\")\n",
    "print (f\"Sample size accuracy v2: {accuracies['AI_N_v2']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5ec77509",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AI_sim</th>\n",
       "      <th>Rev_sim</th>\n",
       "      <th>AI_sim_v2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AI_sim Rev_sim  AI_sim_v2\n",
       "0      no      no          0\n",
       "1      no      no          0\n",
       "2      no      no          0\n",
       "3      no      no          0\n",
       "4      no      no          0\n",
       "5      no      no          0\n",
       "6      no      no          0\n",
       "7      no      no          0\n",
       "8      no      no          0\n",
       "9      no      no          0\n",
       "10     no      no          0\n",
       "11     no      no          0\n",
       "12    yes      no          1\n",
       "13     no      no          0\n",
       "14     no      no          1\n",
       "15    yes      no          1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_testing[[\"AI_sim\", \"Rev_sim\", \"AI_sim_v2\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "25e58bc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arms accuracy v2: 0.6875\n"
     ]
    }
   ],
   "source": [
    "accuracies['AI_arms_v2'] = accuracy_score(df_testing.Rev_arms, df_testing.AI_arms_v2)\n",
    "\n",
    "print (f\"Arms accuracy v2: {accuracies['AI_arms_v2']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "17fdc80b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rev_countries</th>\n",
       "      <th>AI_countries_v2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US</td>\n",
       "      <td>CA,US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>US</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US</td>\n",
       "      <td>US,XX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DE</td>\n",
       "      <td>CA,US,XX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>US</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>US,PR</td>\n",
       "      <td>TW,US,XX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>US</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>US</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>US</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>DE</td>\n",
       "      <td>CA,HT,JE,US,XX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>GE,KE,MY,PH,ZA,TZ,UG,ZM,BR,CN,HT,MZ,PE,RU,TH,UA</td>\n",
       "      <td>CA,CH,GB,US,XX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>BD</td>\n",
       "      <td>BD,BE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>PE,ZA</td>\n",
       "      <td>US,XX,ZA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ZA,TZ,UG</td>\n",
       "      <td>MX,US,XX,ZA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>US,BR,CN,HT,IN,KE,MW,PE,ZA,TH,UG,VN,ZW,ES</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ZA</td>\n",
       "      <td>US,ZA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Rev_countries AI_countries_v2\n",
       "0                                                US           CA,US\n",
       "1                                                US              US\n",
       "2                                                US           US,XX\n",
       "3                                                DE        CA,US,XX\n",
       "4                                                US              US\n",
       "5                                             US,PR        TW,US,XX\n",
       "6                                                US              US\n",
       "7                                                US              US\n",
       "8                                                US              US\n",
       "9                                                DE  CA,HT,JE,US,XX\n",
       "10  GE,KE,MY,PH,ZA,TZ,UG,ZM,BR,CN,HT,MZ,PE,RU,TH,UA  CA,CH,GB,US,XX\n",
       "11                                               BD           BD,BE\n",
       "12                                            PE,ZA        US,XX,ZA\n",
       "13                                         ZA,TZ,UG     MX,US,XX,ZA\n",
       "14        US,BR,CN,HT,IN,KE,MW,PE,ZA,TH,UG,VN,ZW,ES              US\n",
       "15                                               ZA           US,ZA"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_testing[[\"Rev_countries\", \"AI_countries_v2\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "67815a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "exact_match = []\n",
    "approximate_match = []\n",
    "for i in range(len(df_testing)):\n",
    "    countries_gt = set(df_testing.Rev_countries.iloc[i].split(\",\"))\n",
    "    countries_pred = set(df_testing.AI_countries_v2.iloc[i].split(\",\"))\n",
    "    exact_match.append(int(countries_gt == countries_pred))\n",
    "    \n",
    "    is_approximate_match = True\n",
    "    for c in countries_gt:\n",
    "        if c not in countries_pred and \"XX\" not in countries_pred:\n",
    "            is_approximate_match = False\n",
    "            \n",
    "    for c in countries_pred:\n",
    "        if c not in countries_gt:\n",
    "            is_approximate_match = False\n",
    "            \n",
    "    approximate_match.append(int(is_approximate_match))\n",
    "    \n",
    "df_testing[\"is_country_exact_match\"] = exact_match\n",
    "df_testing[\"is_country_approximate_match\"] = approximate_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9c39e921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Countries accuracy v2: 0.3125\n",
      "Countries accuracy v2 including approximate matches: 0.3125\n"
     ]
    }
   ],
   "source": [
    "accuracies['AI_countries_v2'] = df_testing[\"is_country_exact_match\"].mean()\n",
    "accuracies['is_country_approximate_match'] = df_testing[\"is_country_approximate_match\"].mean()\n",
    "\n",
    "print (f\"Countries accuracy v2: {accuracies['AI_countries_v2']}\")\n",
    "print (f\"Countries accuracy v2 including approximate matches: {accuracies['is_country_approximate_match']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "30395d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subtotals = pd.DataFrame()\n",
    "for idx, c in enumerate(df_testing.columns):\n",
    "    last_row = \"\"\n",
    "    if idx == 0:\n",
    "        last_row = \"ACCURACY\"\n",
    "    elif c in accuracies:\n",
    "        last_row = accuracies[c]\n",
    "    \n",
    "    df_subtotals[c] = [\"\", last_row]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "39e3bdb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_testing_with_subtotals = pd.concat([df_testing, df_subtotals]).drop(columns=\"pages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6488e4bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Protocol</th>\n",
       "      <th>Indication</th>\n",
       "      <th>AI_Indication_v2</th>\n",
       "      <th>Drug_or_biologic</th>\n",
       "      <th>Test_article</th>\n",
       "      <th>Pages</th>\n",
       "      <th>AI_phase</th>\n",
       "      <th>AI_phase_v2</th>\n",
       "      <th>Rev_phase</th>\n",
       "      <th>AI_SAP</th>\n",
       "      <th>...</th>\n",
       "      <th>Rev_sim</th>\n",
       "      <th>AI_risk</th>\n",
       "      <th>Rev_risk</th>\n",
       "      <th>Rev_arms</th>\n",
       "      <th>AI_arms_v2</th>\n",
       "      <th>Rev_countries</th>\n",
       "      <th>AI_countries_v2</th>\n",
       "      <th>CTGov_countries</th>\n",
       "      <th>is_country_exact_match</th>\n",
       "      <th>is_country_approximate_match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NCT00752856</td>\n",
       "      <td>HIV</td>\n",
       "      <td>HIV</td>\n",
       "      <td>drug</td>\n",
       "      <td>raltegravir_lopinavir_ritonavir</td>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>high</td>\n",
       "      <td>high</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>US</td>\n",
       "      <td>CA,US</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NCT01896921</td>\n",
       "      <td>HIV</td>\n",
       "      <td>HIV</td>\n",
       "      <td>drug</td>\n",
       "      <td>maraviroc_integrase_inhib</td>\n",
       "      <td>29</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>high</td>\n",
       "      <td>high</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "      <td>US</td>\n",
       "      <td>US</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NCT01933594</td>\n",
       "      <td>HIV</td>\n",
       "      <td>HIV</td>\n",
       "      <td>drug</td>\n",
       "      <td>romidepsin</td>\n",
       "      <td>140</td>\n",
       "      <td>1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1/2</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>high</td>\n",
       "      <td>low</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>US</td>\n",
       "      <td>US,XX</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NCT02217904</td>\n",
       "      <td>HIV</td>\n",
       "      <td>HIV</td>\n",
       "      <td>drug</td>\n",
       "      <td>islatravir</td>\n",
       "      <td>114</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>med</td>\n",
       "      <td>low</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>DE</td>\n",
       "      <td>CA,US,XX</td>\n",
       "      <td>DE</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NCT02263326</td>\n",
       "      <td>HIV</td>\n",
       "      <td>HIV</td>\n",
       "      <td>drug</td>\n",
       "      <td>dolutegravir_lamivudin</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>med</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>US</td>\n",
       "      <td>US</td>\n",
       "      <td>US</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NCT02707861</td>\n",
       "      <td>HIV</td>\n",
       "      <td>HIV</td>\n",
       "      <td>biologic</td>\n",
       "      <td>ibalizumab</td>\n",
       "      <td>106</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>high</td>\n",
       "      <td>med</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>US,PR</td>\n",
       "      <td>TW,US,XX</td>\n",
       "      <td>US,PR</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NCT02788175</td>\n",
       "      <td>HIV</td>\n",
       "      <td>HIV</td>\n",
       "      <td>biologic</td>\n",
       "      <td>vedolizumab</td>\n",
       "      <td>55</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>high</td>\n",
       "      <td>med</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "      <td>US</td>\n",
       "      <td>US</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NCT02946047</td>\n",
       "      <td>HIV</td>\n",
       "      <td>HIV</td>\n",
       "      <td>drug</td>\n",
       "      <td>ixazomib</td>\n",
       "      <td>83</td>\n",
       "      <td>1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1/2</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>high</td>\n",
       "      <td>high</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "      <td>US</td>\n",
       "      <td>US</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NCT03262441</td>\n",
       "      <td>HIV</td>\n",
       "      <td>HIV</td>\n",
       "      <td>drug</td>\n",
       "      <td>mycophenolate_mofetil</td>\n",
       "      <td>39</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>high</td>\n",
       "      <td>high</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "      <td>US</td>\n",
       "      <td>US</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NCT03351699</td>\n",
       "      <td>HIV</td>\n",
       "      <td>HIV</td>\n",
       "      <td>drug</td>\n",
       "      <td>MK-4250</td>\n",
       "      <td>87</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>high</td>\n",
       "      <td>med</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>DE</td>\n",
       "      <td>CA,HT,JE,US,XX</td>\n",
       "      <td>DE</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NCT02342886</td>\n",
       "      <td>TB</td>\n",
       "      <td>TB</td>\n",
       "      <td>drug</td>\n",
       "      <td>moxifloxacin</td>\n",
       "      <td>112</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>GE,KE,MY,PH,ZA,TZ,UG,ZM,BR,CN,HT,MZ,PE,RU,TH,UA</td>\n",
       "      <td>CA,CH,GB,US,XX</td>\n",
       "      <td>GE,KE,MY,PH,ZA,TZ,UG,ZM,BR,CN,HT,MZ,PE,RU,TH,UA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NCT02153528</td>\n",
       "      <td>TB</td>\n",
       "      <td>TB</td>\n",
       "      <td>drug</td>\n",
       "      <td>rifampicin</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>high</td>\n",
       "      <td>med</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>BD</td>\n",
       "      <td>BD,BE</td>\n",
       "      <td>BD</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NCT02583048</td>\n",
       "      <td>TB</td>\n",
       "      <td>TB</td>\n",
       "      <td>drug</td>\n",
       "      <td>bedaquiline_delamanid</td>\n",
       "      <td>119</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>med</td>\n",
       "      <td>low</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>PE,ZA</td>\n",
       "      <td>US,XX,ZA</td>\n",
       "      <td>PE,ZA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NCT02193776</td>\n",
       "      <td>TB</td>\n",
       "      <td>TB</td>\n",
       "      <td>drug</td>\n",
       "      <td>bedaquiline_moxifloxacin</td>\n",
       "      <td>112</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>ZA,TZ,UG</td>\n",
       "      <td>MX,US,XX,ZA</td>\n",
       "      <td>ZA,TZ,UG</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>NCT02410772</td>\n",
       "      <td>TB</td>\n",
       "      <td>TB</td>\n",
       "      <td>drug</td>\n",
       "      <td>rifapentine_moxifloxacin</td>\n",
       "      <td>248</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>yes</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>US,BR,CN,HT,IN,KE,MW,PE,ZA,TH,UG,VN,ZW,ES</td>\n",
       "      <td>US</td>\n",
       "      <td>US,BR,CN,HT,IN,KE,MW,PE,ZA,TH,UG,VN,ZW,ES</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NCT02114684</td>\n",
       "      <td>TB</td>\n",
       "      <td>TB</td>\n",
       "      <td>drug</td>\n",
       "      <td>moxifloxacin</td>\n",
       "      <td>58</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1/2</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>ZA</td>\n",
       "      <td>US,ZA</td>\n",
       "      <td>ZA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ACCURACY</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.6875</td>\n",
       "      <td></td>\n",
       "      <td>0.3125</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.6875</td>\n",
       "      <td></td>\n",
       "      <td>0.3125</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.3125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Protocol Indication AI_Indication_v2 Drug_or_biologic  \\\n",
       "0   NCT00752856        HIV              HIV            drug    \n",
       "1   NCT01896921        HIV              HIV            drug    \n",
       "2   NCT01933594        HIV              HIV            drug    \n",
       "3   NCT02217904        HIV              HIV             drug   \n",
       "4   NCT02263326        HIV              HIV            drug    \n",
       "5   NCT02707861        HIV              HIV         biologic   \n",
       "6   NCT02788175        HIV              HIV         biologic   \n",
       "7   NCT02946047        HIV              HIV            drug    \n",
       "8   NCT03262441        HIV              HIV            drug    \n",
       "9   NCT03351699        HIV              HIV            drug    \n",
       "10  NCT02342886         TB               TB            drug    \n",
       "11  NCT02153528         TB               TB            drug    \n",
       "12  NCT02583048         TB               TB            drug    \n",
       "13  NCT02193776         TB               TB            drug    \n",
       "14  NCT02410772         TB               TB            drug    \n",
       "15  NCT02114684         TB               TB            drug    \n",
       "0                                                              \n",
       "1      ACCURACY                                                \n",
       "\n",
       "                       Test_article Pages AI_phase AI_phase_v2 Rev_phase  \\\n",
       "0   raltegravir_lopinavir_ritonavir    57        1         2.0         2   \n",
       "1         maraviroc_integrase_inhib    29        3         3.0         3   \n",
       "2                        romidepsin   140        1         1.5       1/2   \n",
       "3                        islatravir   114        1         1.0         1   \n",
       "4            dolutegravir_lamivudin    47        0         2.0         3   \n",
       "5                        ibalizumab   106        3         3.0         3   \n",
       "6                       vedolizumab    55        3         1.0         1   \n",
       "7                          ixazomib    83        1         1.5       1/2   \n",
       "8             mycophenolate_mofetil    39        2         2.0         2   \n",
       "9                           MK-4250    87        1         1.0         1   \n",
       "10                     moxifloxacin   112        2         3.0         3   \n",
       "11                       rifampicin    54        1         1.0         3   \n",
       "12            bedaquiline_delamanid   119        2         2.0         2   \n",
       "13         bedaquiline_moxifloxacin   112        2         2.0         2   \n",
       "14         rifapentine_moxifloxacin   248        3         3.0         3   \n",
       "15                     moxifloxacin    58        2         2.0       1/2   \n",
       "0                                                                          \n",
       "1                                              0.5      0.6875             \n",
       "\n",
       "    AI_SAP  ... Rev_sim AI_risk Rev_risk Rev_arms AI_arms_v2  \\\n",
       "0       no  ...      no    high     high        2          2   \n",
       "1       no  ...      no    high     high        1          1   \n",
       "2       no  ...      no    high      low        8          3   \n",
       "3      yes  ...      no     med      low        1          1   \n",
       "4       no  ...      no     NaN      med        2          2   \n",
       "5       no  ...      no    high      med        2          2   \n",
       "6       no  ...      no    high      med        1          1   \n",
       "7       no  ...      no    high     high        4          1   \n",
       "8       no  ...      no    high     high        1          1   \n",
       "9       no  ...      no    high      med        5          3   \n",
       "10      no  ...      no     med      med        5          2   \n",
       "11      no  ...      no    high      med        2          2   \n",
       "12      no  ...      no     med      low        3          3   \n",
       "13      no  ...      no     med      med        3          3   \n",
       "14     yes  ...      no     low      low        3          1   \n",
       "15      no  ...      no     low      low        2          2   \n",
       "0           ...                                                \n",
       "1   0.3125  ...                                       0.6875   \n",
       "\n",
       "                                      Rev_countries AI_countries_v2  \\\n",
       "0                                                US           CA,US   \n",
       "1                                                US              US   \n",
       "2                                                US           US,XX   \n",
       "3                                                DE        CA,US,XX   \n",
       "4                                                US              US   \n",
       "5                                             US,PR        TW,US,XX   \n",
       "6                                                US              US   \n",
       "7                                                US              US   \n",
       "8                                                US              US   \n",
       "9                                                DE  CA,HT,JE,US,XX   \n",
       "10  GE,KE,MY,PH,ZA,TZ,UG,ZM,BR,CN,HT,MZ,PE,RU,TH,UA  CA,CH,GB,US,XX   \n",
       "11                                               BD           BD,BE   \n",
       "12                                            PE,ZA        US,XX,ZA   \n",
       "13                                         ZA,TZ,UG     MX,US,XX,ZA   \n",
       "14        US,BR,CN,HT,IN,KE,MW,PE,ZA,TH,UG,VN,ZW,ES              US   \n",
       "15                                               ZA           US,ZA   \n",
       "0                                                                     \n",
       "1                                                            0.3125   \n",
       "\n",
       "                                    CTGov_countries is_country_exact_match  \\\n",
       "0                                                US                      0   \n",
       "1                                                US                      1   \n",
       "2                                                US                      0   \n",
       "3                                                DE                      0   \n",
       "4                                                US                      1   \n",
       "5                                             US,PR                      0   \n",
       "6                                                US                      1   \n",
       "7                                                US                      1   \n",
       "8                                                US                      1   \n",
       "9                                                DE                      0   \n",
       "10  GE,KE,MY,PH,ZA,TZ,UG,ZM,BR,CN,HT,MZ,PE,RU,TH,UA                      0   \n",
       "11                                               BD                      0   \n",
       "12                                            PE,ZA                      0   \n",
       "13                                         ZA,TZ,UG                      0   \n",
       "14        US,BR,CN,HT,IN,KE,MW,PE,ZA,TH,UG,VN,ZW,ES                      0   \n",
       "15                                               ZA                      0   \n",
       "0                                                                            \n",
       "1                                                                            \n",
       "\n",
       "   is_country_approximate_match  \n",
       "0                             0  \n",
       "1                             1  \n",
       "2                             0  \n",
       "3                             0  \n",
       "4                             1  \n",
       "5                             0  \n",
       "6                             1  \n",
       "7                             1  \n",
       "8                             1  \n",
       "9                             0  \n",
       "10                            0  \n",
       "11                            0  \n",
       "12                            0  \n",
       "13                            0  \n",
       "14                            0  \n",
       "15                            0  \n",
       "0                                \n",
       "1                        0.3125  \n",
       "\n",
       "[18 rows x 32 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_testing_with_subtotals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0e405a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_testing_with_subtotals.to_excel(cwd + \"/README.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9f82e2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_testing_with_subtotals.to_markdown(cwd + \"/README.md\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:protocols]",
   "language": "python",
   "name": "conda-env-protocols-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
